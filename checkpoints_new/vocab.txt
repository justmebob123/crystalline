<PAD>	0
<UNK>	0
<BOS>	0
<EOS>	0
<MASK>	0
/*	959
*	25340
cllm	371
lattice	917
conversion	91
utilities	98
*/	4536
#include	3745
"../../include/cllm.h"	7
"../../include/bigfixed_core.h"	14
"../../include/bigint_core.h"	21
"../../include/prime_types.h"	7
<stdlib.h>	525
<string.h>	539
<stdio.h>	469
"../include/prime_float_math.h"	231
void	3577
cllm_float_to_bigfixed(bigfixed*	7
output,	161
float*	2191
input,	175
int	6566
n,	364
precision)	105
{	30828
(void)precision;	28
unused	77
parameter	84
-	5509
kept	14
for	10437
api	70
compatibility	49
if	23023
(!output	21
||	6678
!input	84
n	959
<=	1771
0)	3766
return;	3542
(int	3395
i	9723
=	44632
0;	11193
<	9226
n;	490
i++)	4305
big_fixed_from_double(&output[i],	7
(double)input[i]);	7
}	30702
cllm_bigfixed_to_float(float*	7
bigfixed*	105
n)	518
output[i]	49
(float)big_fixed_to_double(&input[i]);	7
cllm_embeddings_to_basis(bigfixed**	7
basis,	133
embeddings,	35
dim,	126
(!basis	28
!embeddings	7
0	1897
dim	567
cllm_float_to_bigfixed(basis[i],	7
&embeddings[i	7
dim],	21
precision);	91
cllm_basis_to_embeddings(float*	7
bigfixed**	105
dim)	168
(!embeddings	21
!basis	42
cllm_bigfixed_to_float(&embeddings[i	7
basis[i],	7
dim);	161
cllm_alloc_bigfixed_basis(int	7
(n	602
return	14273
null;	3094
basis	420
(bigfixed**)malloc(n	35
sizeof(bigfixed*));	42
(!basis)	14
basis[i]	14
(bigfixed*)malloc(dim	28
sizeof(bigfixed));	70
(!basis[i])	7
j	1568
i;	469
j++)	693
free(basis[j]);	7
free(basis);	14
d	882
dim;	406
d++)	350
big_fixed_from_int(&basis[i][d],	7
0);	1148
basis;	21
cllm_free_bigfixed_basis(bigfixed**	7
(basis[i])	7
free(basis[i]);	7
cllm_embedding_to_bigfixed(bigfixed*	7
embedding,	119
cllm_float_to_bigfixed(output,	7
cllm_bigfixed_to_embedding(float*	7
vector,	21
cllm_bigfixed_to_float(embedding,	7
float	4648
cllm_test_conversion_accuracy(float*	7
(!input	21
-1.0f;	49
bigfixed	1491
(bigfixed*)malloc(n	35
output	595
(float*)malloc(n	7
sizeof(float));	1575
(!bigfixed	7
!output)	56
(bigfixed)	7
free(bigfixed);	14
(output)	35
free(output);	91
cllm_float_to_bigfixed(bigfixed,	7
cllm_bigfixed_to_float(output,	7
bigfixed,	7
n);	168
max_error	28
0.0f;	1554
error	56
prime_fabsf(output[i]	7
input[i]);	7
(error	42
>	2877
max_error)	7
error;	7
max_error;	14
cllm_print_conversion_stats(float*	7
cllm_test_conversion_accuracy(input,	7
printf("conversion	7
statistics:\n");	77
printf("	1617
elements:	7
%d\n",	553
precision:	49
%d	357
bits\n",	7
max	168
error:	21
%.10e\n",	7
max_error);	7
(max_error	21
1e-6f)	21
status:	28
excellent	7
1e-6)\n");	7
else	1323
1e-4f)	7
good	28
1e-4)\n");	7
1e-2f)	7
acceptable	7
1e-2)\n");	14
warning	70
>=	1267
pure	70
crystalline	406
embeddings	399
implementation	315
implements	119
crystallineembeddings	21
with	1071
lll-reduced	14
exact	35
token	826
positions,	7
and	1197
morphology	35
graph.	7
implementation:	35
uses	287
only	91
arbitrary	105
precision	343
mathematics.	14
no	322
external	49
math	63
libraries	14
(math.h,	14
gmp,	14
etc.)	35
"cllm_pure_crystalline.h"	21
helper	147
function	224
to	3661
allocate	966
matrix	350
static	1519
allocate_bigfixed_matrix(uint32_t	7
rows,	28
uint32_t	2163
cols,	7
(bigfixed**)malloc(rows	7
(!matrix)	14
(uint32_t	1876
rows;	70
matrix[i]	7
(bigfixed*)malloc(cols	7
(!matrix[i])	7
//	25991
cleanup	287
on	455
failure	56
free(matrix[j]);	7
free(matrix);	21
initialize	1260
each	301
cols;	77
bigint	1582
structures	63
matrix[i][j].integer_part	7
(bigint*)malloc(sizeof(bigint));	385
matrix[i][j].fractional_part	7
(!matrix[i][j].integer_part	7
!matrix[i][j].fractional_part)	7
k	420
k++)	91
l	70
l++)	28
big_free(matrix[k][l].integer_part);	7
free(matrix[k][l].integer_part);	7
big_free(matrix[k][l].fractional_part);	7
free(matrix[k][l].fractional_part);	7
free(matrix[k]);	7
(j	28
j;	126
big_free(matrix[i][l].integer_part);	7
free(matrix[i][l].integer_part);	7
big_free(matrix[i][l].fractional_part);	7
free(matrix[i][l].fractional_part);	7
free(matrix[i]);	14
big_init(matrix[i][j].integer_part);	7
big_init(matrix[i][j].fractional_part);	7
matrix[i][j].scale_bits	7
precision;	56
matrix[i][j].negative	7
matrix;	7
free	777
free_bigfixed_matrix(bigfixed**	7
matrix,	21
cols)	21
(matrix[i])	7
(matrix[i][j].integer_part)	7
big_free(matrix[i][j].integer_part);	7
free(matrix[i][j].integer_part);	7
(matrix[i][j].fractional_part)	7
big_free(matrix[i][j].fractional_part);	7
free(matrix[i][j].fractional_part);	7
create	812
new	168
structure	343
crystallineembeddings*	14
crystalline_embeddings_create(uint32_t	7
vocab_size,	91
lattice_dim)	7
(vocab_size	14
==	4501
lattice_dim	14
fprintf(stderr,	2037
"error:	1141
vocab_size	378
must	210
be	413
0\n");	140
(crystallineembeddings*)malloc(sizeof(crystallineembeddings));	7
(!embeddings)	28
failed	490
crystallineembeddings\n");	7
embeddings->vocab_size	7
vocab_size;	315
embeddings->lattice_dim	21
lattice_dim;	7
embeddings->basis_optimized	7
false;	2121
embeddings->optimization_epoch	7
embeddings->total_lookups	7
embeddings->cache_hits	7
embeddings->avg_lookup_time	7
0.0;	777
(identity	7
initially)	7
embeddings->lattice_basis	7
allocate_bigfixed_matrix(lattice_dim,	14
lattice_dim,	112
256);	49
(!embeddings->lattice_basis)	7
free(embeddings);	63
inverse	210
embeddings->inverse_basis	7
(!embeddings->inverse_basis)	7
free_bigfixed_matrix(embeddings->lattice_basis,	56
lattice_dim);	119
array	399
embeddings->tokens	7
(crystallinetoken**)calloc(vocab_size,	7
sizeof(crystallinetoken*));	7
(!embeddings->tokens)	7
free_bigfixed_matrix(embeddings->inverse_basis,	49
positions	56
embeddings->token_positions	7
allocate_bigfixed_matrix(vocab_size,	7
(!embeddings->token_positions)	7
free(embeddings->tokens);	42
primes	210
embeddings->token_primes	7
(uint64_t*)calloc(vocab_size,	7
sizeof(uint64_t));	35
(!embeddings->token_primes)	7
free_bigfixed_matrix(embeddings->token_positions,	35
graph	14
embeddings->morphology_graph	7
(uint32_t**)malloc(vocab_size	7
sizeof(uint32_t*));	7
(!embeddings->morphology_graph)	7
free(embeddings->token_primes);	28
embeddings->morphology_graph[i]	7
(uint32_t*)calloc(max_derived_tokens,	7
sizeof(uint32_t));	280
(!embeddings->morphology_graph[i])	7
free(embeddings->morphology_graph[j]);	7
free(embeddings->morphology_graph);	21
counts	21
embeddings->morphology_counts	7
(uint8_t*)calloc(vocab_size,	7
sizeof(uint8_t));	7
(!embeddings->morphology_counts)	7
free(embeddings->morphology_graph[i]);	14
embeddings;	7
crystalline_embeddings_free(crystallineembeddings*	7
embeddings)	14
(embeddings->morphology_counts)	7
free(embeddings->morphology_counts);	7
(embeddings->morphology_graph)	7
embeddings->vocab_size;	7
(embeddings->morphology_graph[i])	7
(embeddings->token_primes)	7
(embeddings->token_positions)	7
embeddings->vocab_size,	7
embeddings->lattice_dim);	21
tokens	595
(but	7
don't	84
the	1015
objects	7
themselves	7
they're	28
owned	21
by	420
caller)	7
(embeddings->tokens)	7
(embeddings->inverse_basis)	7
embeddings->lattice_dim,	14
(embeddings->lattice_basis)	7
add	427
bool	1148
crystalline_embeddings_add_token(crystallineembeddings*	7
crystallinetoken*	28
token)	42
!token)	21
null	224
or	315
token\n");	7
(token->token_id	7
embeddings->vocab_size)	21
token_id	203
%u	210
%u\n",	413
token->token_id,	7
embeddings->vocab_size);	21
store	126
pointer	56
embeddings->tokens[token->token_id]	7
token;	42
prime	1323
embeddings->token_primes[token->token_id]	7
token->prime;	7
copy	371
position	448
(from	14
ulam	147
spiral	245
coordinates)	7
&&	2044
3;	301
big_fixed_assign(&embeddings->token_positions[token->token_id][i],	7
&token->lattice_coords[i]);	7
true;	994
get	665
from	931
crystalline_embeddings_get_token(crystallineembeddings*	7
token_id)	42
embeddings\n");	28
(token_id	140
token_id,	126
embeddings->tokens[token_id];	7
identity	77
crystalline_initialize_basis(crystallineembeddings*	7
set	350
embeddings->lattice_dim;	28
(i	392
j)	56
1.0	168
big_from_int(embeddings->lattice_basis[i][j].integer_part,	14
1);	1498
big_from_int(embeddings->lattice_basis[i][j].fractional_part,	14
0.0	98
embeddings->lattice_basis[i][j].negative	7
(same	21
as	231
identity)	7
big_from_int(embeddings->inverse_basis[i][j].integer_part,	14
big_from_int(embeddings->inverse_basis[i][j].fractional_part,	14
embeddings->inverse_basis[i][j].negative	7
compute	1197
(currently	7
just	140
copies	14
token's	28
lattice_coords)	7
crystalline_compute_token_position(crystallineembeddings*	7
position[3])	7
!position)	7
position\n");	28
stored	49
big_fixed_assign(&position[i],	7
&embeddings->token_positions[token_id][i]);	7
operations	245
"../../include/cllm_pure_crystalline.h"	7
"../../include/prime_math_custom.h"	7
"../../include/prime_bigint_transcendental.h"	7
"../../include/bigfixed_constants.h"	7
#define	350
prime_cache_size	14
10000	21
uint64_t	2436
prime_cache[prime_cache_size];	14
prime_cache_initialized	28
integer	273
square	63
root	224
using	665
newton's	35
method	21
floating	7
point	70
isqrt(uint64_t	14
3)	70
1;	1897
initial	56
guess	42
x	1176
y	224
(x	644
+	6062
1)	1043
/	3507
2;	630
method:	21
x_new	14
n/x)	21
2	665
while	1015
(y	119
x)	497
y;	140
x;	217
init_prime_cache(void)	14
(prime_cache_initialized)	14
prime_cache[0]	14
prime_cache[1]	14
count	749
candidate	147
5;	91
(count	119
prime_cache_size)	35
is_prime	112
sqrt_cand	14
isqrt(candidate);	7
prime_cache[i]	35
sqrt_cand;	14
(candidate	21
%	1022
break;	1267
(is_prime)	42
prime_cache[count++]	14
candidate;	84
+=	2709
crystalline_is_prime(uint64_t	7
2)	434
sqrt_n	21
isqrt(n);	14
(uint64_t	294
sqrt_n;	21
crystalline_get_nth_prime(uint32_t	7
init_prime_cache();	42
prime_cache[n];	14
prime_cache_size;	42
prime_cache[prime_cache_size	21
1]	168
(crystalline_is_prime(candidate))	7
count++;	168
crystalline_factorize(uint64_t	7
number,	14
uint64_t*	147
factors,	21
uint8_t*	7
num_factors)	14
(!factors	7
!num_factors)	7
*num_factors	49
(number	35
(crystalline_is_prime(number))	7
factors[0]	7
number;	21
max_prime_factors)	14
factors[(*num_factors)++]	21
number	686
/=	280
max_prime_factors;	7
1	651
crystalline_compute_ulam_position(uint64_t	7
prime,	238
coords[3],	14
(!coords)	21
needed	175
(!coords[i].integer_part)	7
coords[i].integer_part	7
big_init(coords[i].integer_part);	7
(!coords[i].fractional_part)	7
coords[i].fractional_part	7
big_init(coords[i].fractional_part);	7
coords[i].scale_bits	7
coords[i].negative	7
find	448
index	203
prime_index	84
(prime_cache[i]	21
prime)	245
not	378
in	1596
cache,	28
estimate	119
(prime_index	14
1])	7
approximate:	7
≈	196
ln(prime)	7
simplicity,	14
use	875
10	84
rough	35
(uint32_t)(prime	21
10);	35
bigint*	217
idx	182
big_init(idx);	7
big_from_int(idx,	7
prime_index);	14
radius	210
sqrt(prime_index)	7
radius;	14
radius.integer_part	7
radius.fractional_part	7
big_init(radius.integer_part);	7
big_init(radius.fractional_part);	7
radius.scale_bits	7
radius.negative	7
big_sqrt(&radius,	7
idx,	7
angle	385
golden_angle	91
2π	49
φ²	14
2.39996322972865332	7
radians	70
golden_angle;	21
golden_angle.integer_part	7
golden_angle.fractional_part	7
big_init(golden_angle.integer_part);	7
big_init(golden_angle.fractional_part);	7
golden_angle.scale_bits	7
golden_angle.negative	7
big_fixed_from_double(&golden_angle,	7
2.39996322972865332);	7
angle;	49
angle.integer_part	7
angle.fractional_part	7
big_init(angle.integer_part);	7
big_init(angle.fractional_part);	7
angle.scale_bits	7
angle.negative	7
idx_fixed;	7
idx_fixed.integer_part	7
idx_fixed.fractional_part	7
big_init(idx_fixed.integer_part);	7
big_init(idx_fixed.fractional_part);	7
idx_fixed.scale_bits	7
idx_fixed.negative	7
big_fixed_from_int(&idx_fixed,	7
big_fixed_mul(&angle,	7
&golden_angle,	7
&idx_fixed);	7
cos(angle)	7
cos_angle;	7
cos_angle.integer_part	7
cos_angle.fractional_part	7
big_init(cos_angle.integer_part);	7
big_init(cos_angle.fractional_part);	7
cos_angle.scale_bits	7
cos_angle.negative	7
big_cos(&cos_angle,	7
&angle,	21
big_fixed_mul(&coords[0],	7
&radius,	14
&cos_angle);	7
sin(angle)	7
sin_angle;	7
sin_angle.integer_part	7
sin_angle.fractional_part	7
big_init(sin_angle.integer_part);	7
big_init(sin_angle.fractional_part);	7
sin_angle.scale_bits	7
sin_angle.negative	7
big_sin(&sin_angle,	7
big_fixed_mul(&coords[1],	7
&sin_angle);	7
z	70
ln(prime	7
prime_plus_1	7
big_init(prime_plus_1);	7
big_from_int(prime_plus_1,	7
big_ln(&coords[2],	7
prime_plus_1,	7
temporary	84
bigfixed/bigint	7
big_free(prime_plus_1);	7
free(prime_plus_1);	7
big_free(sin_angle.integer_part);	7
free(sin_angle.integer_part);	7
big_free(sin_angle.fractional_part);	7
free(sin_angle.fractional_part);	7
big_free(cos_angle.integer_part);	7
free(cos_angle.integer_part);	7
big_free(cos_angle.fractional_part);	7
free(cos_angle.fractional_part);	7
big_free(idx_fixed.integer_part);	7
free(idx_fixed.integer_part);	7
big_free(idx_fixed.fractional_part);	7
free(idx_fixed.fractional_part);	7
big_free(angle.integer_part);	7
free(angle.integer_part);	7
big_free(angle.fractional_part);	7
free(angle.fractional_part);	7
big_free(golden_angle.integer_part);	7
free(golden_angle.integer_part);	7
big_free(golden_angle.fractional_part);	7
free(golden_angle.fractional_part);	7
big_free(radius.integer_part);	7
free(radius.integer_part);	7
big_free(radius.fractional_part);	7
free(radius.fractional_part);	7
big_free(idx);	7
free(idx);	7
crystalline_token_create(uint32_t	7
const	2569
char*	1309
token_str,	28
(crystallinetoken*)calloc(1,	7
sizeof(crystallinetoken));	7
(!token)	14
token->token_id	14
token_id;	49
(token_str)	7
strncpy(token->token_str,	14
63);	14
token->token_str[63]	7
'\0';	294
token->prime	7
prime;	70
token->is_root	7
crystalline_is_prime(prime);	7
crystalline_factorize(prime,	7
token->prime_factors,	7
&token->num_factors);	7
coordinates	210
token->lattice_coords[i].integer_part	7
token->lattice_coords[i].fractional_part	7
#pragma	21
gcc	21
diagnostic	21
push	7
ignored	7
"-wstringop-overflow"	7
crystalline_compute_ulam_position(prime,	7
token->lattice_coords,	14
pop	7
(token->is_root)	7
token->root_token_id	14
token->num_neighbors	7
token->usage_count	7
token->root_score	7
1.0;	168
crystalline_token_free(crystallinetoken*	7
(token->lattice_coords[i].integer_part)	7
big_free(token->lattice_coords[i].integer_part);	7
free(token->lattice_coords[i].integer_part);	7
(token->lattice_coords[i].fractional_part)	7
big_free(token->lattice_coords[i].fractional_part);	7
free(token->lattice_coords[i].fractional_part);	7
free(token);	7
crystalline_lattice_distance(const	7
pos1[3],	7
pos2[3],	7
distance)	14
(!pos1	21
!pos2	7
!distance)	7
distance	336
(!distance->integer_part)	7
distance->integer_part	7
big_init(distance->integer_part);	7
(!distance->fractional_part)	7
distance->fractional_part	7
big_init(distance->fractional_part);	7
diff[3];	7
diff_sq[3];	7
sum;	175
diff[i].integer_part	7
diff[i].fractional_part	7
big_init(diff[i].integer_part);	7
big_init(diff[i].fractional_part);	7
diff_sq[i].integer_part	7
diff_sq[i].fractional_part	7
big_init(diff_sq[i].integer_part);	7
big_init(diff_sq[i].fractional_part);	7
sum.integer_part	7
sum.fractional_part	7
big_init(sum.integer_part);	7
big_init(sum.fractional_part);	7
big_fixed_sub(&diff[i],	7
&pos1[i],	7
&pos2[i]);	7
big_fixed_mul(&diff_sq[i],	7
&diff[i],	7
&diff[i]);	7
big_fixed_from_int(&sum,	7
temp;	301
temp.integer_part	7
temp.fractional_part	7
big_init(temp.integer_part);	7
big_init(temp.fractional_part);	7
big_fixed_add(&temp,	7
&sum,	7
&diff_sq[i]);	7
big_free(sum.integer_part);	14
big_free(sum.fractional_part);	14
free(sum.integer_part);	14
free(sum.fractional_part);	14
sum	777
sqrt(sum)	7
first	357
convert	329
big_sqrt	7
sum_int	7
big_init(sum_int);	7
big_fixed_to_bigint_rounded(sum_int,	7
&sum);	7
sqrt	7
big_sqrt(distance,	7
sum_int,	7
big_free(sum_int);	7
free(sum_int);	7
big_free(diff[i].integer_part);	7
big_free(diff[i].fractional_part);	7
free(diff[i].integer_part);	7
free(diff[i].fractional_part);	7
big_free(diff_sq[i].integer_part);	7
big_free(diff_sq[i].fractional_part);	7
free(diff_sq[i].integer_part);	7
free(diff_sq[i].fractional_part);	7
crystalline_prime_similarity(uint64_t	7
prime1,	56
prime2,	21
similarity)	7
(!similarity)	7
(!similarity->integer_part)	7
similarity->integer_part	7
big_init(similarity->integer_part);	7
(!similarity->fractional_part)	7
similarity->fractional_part	7
big_init(similarity->fractional_part);	7
(prime1	56
prime2)	84
big_fixed_from_double(similarity,	21
1.0);	35
a	1092
b	686
prime2;	21
(b	119
!=	1365
temp	203
b;	259
gcd	196
a;	63
(gcd	56
0.5);	21
double	2968
sim	14
(double)gcd;	7
(sim	7
1.0)	63
sim);	7
crystalline_phase_alignment(uint64_t	7
alignment)	7
(!alignment)	7
(!alignment->integer_part)	7
alignment->integer_part	7
big_init(alignment->integer_part);	7
(!alignment->fractional_part)	7
alignment->fractional_part	7
big_init(alignment->fractional_part);	7
phase_diff	21
π	77
big_pi	14
pi;	35
pi.integer_part	7
pi.fractional_part	7
big_init(pi.integer_part);	7
big_init(pi.fractional_part);	7
pi.scale_bits	7
256;	70
pi.negative	7
big_pi(&pi,	7
two_pi;	49
two_pi.integer_part	7
two_pi.fractional_part	7
big_init(two_pi.integer_part);	7
big_init(two_pi.fractional_part);	7
two_pi.scale_bits	7
two_pi.negative	7
two;	63
two.integer_part	7
two.fractional_part	7
big_init(two.integer_part);	7
big_init(two.fractional_part);	7
two.scale_bits	7
two.negative	7
big_fixed_from_int(&two,	7
2);	175
big_fixed_mul(&two_pi,	7
&pi,	7
&two);	21
int64_t	231
diff	238
(int64_t)prime1	7
(int64_t)prime2;	7
diff_fixed;	7
diff_fixed.integer_part	7
diff_fixed.fractional_part	7
big_init(diff_fixed.integer_part);	7
big_init(diff_fixed.fractional_part);	7
diff_fixed.scale_bits	7
diff_fixed.negative	7
(diff	70
?	1078
:	1078
big_fixed_from_int(&diff_fixed,	7
-diff	7
diff);	21
sum_primes	7
prime1	28
sum_fixed;	7
sum_fixed.integer_part	7
sum_fixed.fractional_part	7
big_init(sum_fixed.integer_part);	7
big_init(sum_fixed.fractional_part);	7
sum_fixed.scale_bits	7
sum_fixed.negative	7
big_fixed_from_int(&sum_fixed,	7
sum_primes);	7
numerator;	14
numerator.integer_part	7
numerator.fractional_part	7
big_init(numerator.integer_part);	7
big_init(numerator.fractional_part);	7
numerator.scale_bits	7
numerator.negative	7
big_fixed_mul(&numerator,	7
&two_pi,	7
&diff_fixed);	7
numerator	28
phase_diff;	7
phase_diff.integer_part	7
phase_diff.fractional_part	7
big_init(phase_diff.integer_part);	7
big_init(phase_diff.fractional_part);	7
phase_diff.scale_bits	7
phase_diff.negative	7
big_fixed_div(&phase_diff,	7
&numerator,	14
&sum_fixed);	7
cos(phase_diff)	7
cos_phase;	7
cos_phase.integer_part	7
cos_phase.fractional_part	7
big_init(cos_phase.integer_part);	7
big_init(cos_phase.fractional_part);	7
cos_phase.scale_bits	7
cos_phase.negative	7
big_cos(&cos_phase,	7
&phase_diff,	7
(1	133
cos(phase_diff))	14
one;	98
one.integer_part	7
one.fractional_part	7
big_init(one.integer_part);	7
big_init(one.fractional_part);	7
one.scale_bits	7
one.negative	7
big_fixed_from_int(&one,	7
one_plus_cos;	7
one_plus_cos.integer_part	7
one_plus_cos.fractional_part	7
big_init(one_plus_cos.integer_part);	7
big_init(one_plus_cos.fractional_part);	7
one_plus_cos.scale_bits	7
one_plus_cos.negative	7
big_fixed_add(&one_plus_cos,	7
&one,	133
&cos_phase);	7
alignment	28
big_fixed_div(alignment,	7
&one_plus_cos,	7
big_free(one_plus_cos.integer_part);	7
free(one_plus_cos.integer_part);	7
big_free(one_plus_cos.fractional_part);	7
free(one_plus_cos.fractional_part);	7
big_free(one.integer_part);	7
free(one.integer_part);	7
big_free(one.fractional_part);	7
free(one.fractional_part);	7
big_free(cos_phase.integer_part);	7
free(cos_phase.integer_part);	7
big_free(cos_phase.fractional_part);	7
free(cos_phase.fractional_part);	7
big_free(phase_diff.integer_part);	7
free(phase_diff.integer_part);	7
big_free(phase_diff.fractional_part);	7
free(phase_diff.fractional_part);	7
big_free(numerator.integer_part);	7
free(numerator.integer_part);	7
big_free(numerator.fractional_part);	7
free(numerator.fractional_part);	7
big_free(sum_fixed.integer_part);	7
free(sum_fixed.integer_part);	7
big_free(sum_fixed.fractional_part);	7
free(sum_fixed.fractional_part);	7
big_free(diff_fixed.integer_part);	7
free(diff_fixed.integer_part);	7
big_free(diff_fixed.fractional_part);	7
free(diff_fixed.fractional_part);	7
big_free(two.integer_part);	7
free(two.integer_part);	7
big_free(two.fractional_part);	7
free(two.fractional_part);	7
big_free(two_pi.integer_part);	7
free(two_pi.integer_part);	7
big_free(two_pi.fractional_part);	7
free(two_pi.fractional_part);	7
big_free(pi.integer_part);	7
free(pi.integer_part);	7
big_free(pi.fractional_part);	7
free(pi.fractional_part);	7
attention	770
mechanism	21
multi-head	35
self-attention	7
<immintrin.h>	28
"../include/cllm.h"	133
"../include/cllm_inference.h"	70
"../include/cllm_simd_utils.h"	21
"../include/cllm_cache.h"	21
forward	294
declarations	42
missing	21
functions	476
prime_exp(double	21
x);	252
prime_sqrt(double	21
/**	3577
softmax	154
@param	2296
input/output	112
size	882
softmax(float*	7
x,	420
size)	287
(!x	77
numerical	147
stability	161
max_val	98
x[0];	7
size;	385
(x[i]	42
max_val)	28
x[i];	28
exp	70
x[i]	112
prime_exp(x[i]	7
max_val);	21
normalize	252
(sum	28
1e-8f)	84
scaled	21
dot-product	14
single	105
head	175
attention(q,	7
k,	210
v)	35
softmax(q	7
k^t	7
sqrt(d_k))	7
v	483
query	168
vector	350
[head_dim]	42
keys	42
key	133
[seq_len	105
head_dim]	14
values	175
value	385
head_dim	455
dimension	350
per	210
seq_len	686
sequence	280
length	147
scaled_dot_product_attention(float*	7
query,	21
keys,	21
values,	42
head_dim,	42
seq_len)	91
(!query	14
!keys	35
!values	21
!output	84
scale	420
1.0f	238
prime_sqrt((float)head_dim);	7
scores	63
(float*)malloc(seq_len	56
(!scores)	7
simd	56
dot	210
product:	21
scores[i]	28
·	7
keys[i]	7
sqrt(head_dim)	7
seq_len;	455
prefetch	35
next	224
better	56
cache	490
utilization	35
prefetch_read(&keys[(i	7
head_dim]);	14
dot_product(query,	7
&keys[i	14
head_dim],	7
head_dim)	14
scale;	301
apply	679
weights	469
softmax(scores,	7
seq_len);	84
weighted	14
of	1113
memset(output,	28
0,	847
prefetch_read(&values[(i	7
values[i]	14
score	63
scores[i];	14
j_vec	14
(head_dim	7
8)	182
8;	105
__m256	224
vscore	7
_mm256_set1_ps(score);	7
vectorized	84
accumulation	175
(;	126
j_vec;	14
vval	7
_mm256_loadu_ps(&values[i	7
j]);	56
vout	14
_mm256_loadu_ps(&output[j]);	7
_mm256_fmadd_ps(vscore,	7
vval,	7
vout);	14
_mm256_storeu_ps(&output[j],	7
scalar	119
remainder	119
head_dim;	203
output[j]	14
values[i	7
j];	35
free(scores);	7
pass	399
layer	1057
parameters	294
input	427
embedding_dim]	70
key_cache	14
cached	77
(can	14
null)	189
value_cache	14
cllm_attention_forward(attentionlayer*	7
layer,	84
key_cache,	21
value_cache,	21
(!layer	49
num_heads	112
layer->num_heads;	14
layer->head_dim;	28
embedding_dim	343
buffers	231
q,	154
projections	49
queries	35
(!queries	28
!values)	14
(queries)	7
free(queries);	42
(keys)	7
free(keys);	42
(values)	7
free(values);	42
project	77
directly	14
full	224
implementation,	35
these	42
would	182
separate	14
projection	91
matrices	35
(void)num_heads;	7
used	105
structure,	14
suppress	63
(void)head_dim;	7
pos	308
pos++)	84
input_vec	21
&input[pos	21
embedding_dim];	77
h	539
num_heads;	91
h++)	147
size_t	2443
weight_idx	63
layer->query_lattice[weight_idx]	14
input_vec[h	63
i];	119
queries[pos	21
d]	91
layer->key_lattice[weight_idx]	14
keys[pos	21
layer->value_lattice[weight_idx]	14
values[pos	21
keys/values	7
available	105
(key_cache)	14
memcpy(keys,	7
(value_cache)	14
memcpy(values,	7
&queries[pos	14
head_dim];	70
head_keys	7
&keys[h	7
head_values	7
&values[h	7
head_output	14
&output[pos	14
this	581
scaled_dot_product_attention(query,	7
head_keys,	7
head_values,	7
head_output,	7
update	609
caches	14
provided	42
memcpy(key_cache,	7
memcpy(value_cache,	7
kv	7
(for	112
autoregressive	7
generation)	7
inf	91
inference	175
engine	42
state	567
layer_idx	21
cllm_multi_head_attention(cllminference*	7
inf,	49
layer_idx,	7
(!inf	49
(layer_idx	7
(int)inf->model->num_layers)	7
attentionlayer*	105
&inf->model->attention_layers[layer_idx];	7
calculate	476
offsets	7
inf->model->embedding_dim;	7
cache_offset	7
inf->kv_cache_size	7
embedding_dim;	168
inf->key_cache	7
&inf->key_cache[cache_offset]	7
inf->value_cache	7
&inf->value_cache[cache_offset]	7
cllm_attention_forward(layer,	7
heads	7
cllm_attention_init(attentionlayer*	7
num_heads,	14
layer->num_heads	21
layer->head_dim	7
weight_size	21
layer->query_lattice	14
(float*)calloc(weight_size,	42
layer->key_lattice	14
layer->value_lattice	14
(!layer->query_lattice	7
!layer->key_lattice	7
!layer->value_lattice)	7
cllm_attention_free(layer);	7
cllm_attention_free(attentionlayer*	7
layer)	28
(!layer)	14
(layer->query_lattice)	7
free(layer->query_lattice);	7
(layer->key_lattice)	7
free(layer->key_lattice);	7
(layer->value_lattice)	7
free(layer->value_lattice);	7
backward	308
training	980
computes	21
gradients	903
all	882
model	952
"cllm_training.h"	84
"cllm_utils.h"	14
zero	308
gradient	1001
before	35
cllm_zero_all_gradients(cllmtraining*	7
training)	98
(!training	161
!training->model)	21
cllmmodel*	259
training->model;	84
main	98
buffer	266
(only	7
are	308
here)	7
(training->gradients)	28
embed_size	56
model->vocab_size	91
model->embedding_dim;	252
memset(training->gradients,	7
(training->attention_grads)	35
model->num_layers;	189
&model->attention_layers[i];	49
lattice_size	28
(training->attention_grads[i].query_lattice)	7
memset(training->attention_grads[i].query_lattice,	7
(training->attention_grads[i].key_lattice)	7
memset(training->attention_grads[i].key_lattice,	7
(training->attention_grads[i].value_lattice)	7
memset(training->attention_grads[i].value_lattice,	7
feed-forward	224
(training->ff_grads)	28
feedforwardlayer*	98
&model->ff_layers[i];	49
(training->ff_grads[i].w1_lattice)	7
memset(training->ff_grads[i].w1_lattice,	7
layer->input_dim	21
layer->hidden_dim	28
(training->ff_grads[i].w2_lattice)	7
memset(training->ff_grads[i].w2_lattice,	7
layer->output_dim	21
(training->ff_grads[i].bias1)	7
memset(training->ff_grads[i].bias1,	7
(training->ff_grads[i].bias2)	7
memset(training->ff_grads[i].bias2,	7
norm	420
(training->ln_grads)	14
cllmlayernorm*	49
&model->layer_norms[i];	14
(training->ln_grads[i].gamma)	7
memset(training->ln_grads[i].gamma,	7
layer->dim	14
(training->ln_grads[i].beta)	7
memset(training->ln_grads[i].beta,	7
through	140
normalization	140
backward_layer_norm(float*	7
grad_out,	28
grad_in,	21
ln,	49
grad_gamma,	7
grad_beta,	7
critical:	77
checks	42
(!grad_out	21
!grad_in	21
!x	35
!ln)	14
(!ln->gamma	14
!ln->beta)	14
layernorm	21
has	126
pointers!\n");	21
"	140
gamma=%p,	7
beta=%p\n",	7
(void*)ln->gamma,	7
(void*)ln->beta);	7
mean	189
variance	84
0.0f,	77
var	84
mean;	35
diff;	98
std	49
prime_sqrtf(var	28
1e-5f);	21
inv_std	28
std;	28
grad_var	42
grad_mean	42
x_norm	14
mean)	70
inv_std;	14
w.r.t.	161
gamma	98
beta	63
(grad_gamma)	7
grad_gamma[i]	7
grad_out[i]	21
x_norm;	14
(grad_beta)	7
grad_beta[i]	7
grad_out[i];	7
normalized	42
grad_x_norm	70
ln->gamma[i];	14
accumulate	196
-0.5f	14
-inv_std;	7
grad_in[i]	14
2.0f	252
backward_feed_forward(float*	7
ff,	7
grad_w1,	7
grad_w2,	7
grad_b1,	7
grad_b2)	7
!ff)	14
(!ff->w1_lattice	7
!ff->w2_lattice	7
!ff->bias1	7
!ff->bias2)	7
feedforwardlayer	7
w1_lattice=%p,	7
w2_lattice=%p,	7
bias1=%p,	7
bias2=%p\n",	7
(void*)ff->w1_lattice,	7
(void*)ff->w2_lattice,	7
(void*)ff->bias1,	7
(void*)ff->bias2);	7
input_dim	112
ff->input_dim;	21
hidden_dim	112
ff->hidden_dim;	84
output_dim	84
ff->output_dim;	42
hidden	189
(float*)calloc(hidden_dim,	28
grad_hidden	21
(!hidden	7
!grad_hidden)	7
free(hidden);	28
free(grad_hidden);	35
activations	42
hidden_dim;	84
ff->bias1[h];	14
input_dim;	35
ff->w1_lattice[i	28
h];	14
hidden[h]	21
prime_tanhf(sum);	14
relu	35
tanh	35
activation	91
second	133
o	70
output_dim;	49
o++)	21
w2	28
(grad_w2)	7
grad_w2[h	7
o]	28
grad_out[o];	21
grad_hidden[h]	28
ff->w2_lattice[h	21
bias2	14
(grad_b2)	7
grad_b2[o]	7
tanh_val	49
hidden[h];	14
*=	728
(1.0f	245
tanh_val);	21
derivative	7
memset(grad_in,	7
w1	21
(grad_w1)	7
grad_w1[i	7
h]	28
grad_hidden[h];	42
bias1	14
(grad_b1)	7
grad_b1[h]	7
(simplified)	28
backward_attention(float*	7
attn,	7
grad_query,	7
grad_key,	7
grad_value)	7
!attn)	7
(!attn->query_lattice	14
!attn->key_lattice	14
!attn->value_lattice)	14
attentionlayer	7
query_lattice=%p,	7
key_lattice=%p,	7
value_lattice=%p\n",	7
(void*)attn->query_lattice,	7
(void*)attn->key_lattice,	7
(void*)attn->value_lattice);	7
attn->num_heads	49
attn->head_dim;	63
simplified:	14
require	14
storing	7
now,	168
approximate	35
small	238
memcpy(grad_in,	7
(grad_query)	7
grad_query[i	7
j]	189
grad_out[j]	21
0.1f;	63
(grad_key)	7
grad_key[i	7
(grad_value)	7
grad_value[i	7
internal	42
cllm_backward_impl(cllmtraining*	7
training,	217
uint32_t*	539
input_tokens,	84
target_tokens,	63
batch_size,	133
!training->model	7
!training->gradients)	7
(!input_tokens	14
!target_tokens	14
batch_size	343
embed_dim	700
num_layers	63
cllm_zero_all_gradients(training);	21
pre-allocated	21
(optimization	7
malloc/free	7
overhead)	7
training->backward_embeddings;	7
grad_output	28
training->backward_grad_output;	7
layer_input	35
training->backward_layer_input;	7
layer_grad	7
training->backward_layer_grad;	7
temp_grad	7
training->backward_temp_grad;	7
activation_size	35
embed_dim;	406
check	1414
prevent	98
overflow	98
(activation_size	7
training->backward_buffer_size)	7
(%zu)	7
exceeds	28
(%zu)\n",	7
activation_size,	7
training->backward_buffer_size);	7
batch_size=%d,	7
seq_len=%d,	7
embed_dim=%lu\n",	7
seq_len,	112
embed_dim);	35
memset(embeddings,	7
memset(grad_output,	7
memset(layer_input,	7
memset(layer_grad,	7
memset(temp_grad,	7
simplified	91
layers	245
proper	105
we	252
need	105
initialized	63
(!model->ff_layers	7
!model->attention_layers	7
!model->layer_norms)	14
null!\n");	14
ff_layers=%p,	7
attention_layers=%p,	7
layer_norms=%p\n",	7
(void*)model->ff_layers,	7
(void*)model->attention_layers,	7
(void*)model->layer_norms);	7
(!model->embeddings.embeddings)	21
process	266
batch	833
batch_size;	329
b++)	175
s	161
s++)	70
s;	112
input_tokens[idx];	14
target_id	14
target_tokens[idx];	21
model->vocab_size)	63
continue;	420
embedding	770
embed_src	14
&model->embeddings.embeddings[token_id	42
embed_dim];	196
memcpy(layer_input,	7
embed_src,	14
simple	266
loss	511
(mse	7
target	364
embedding)	14
target_embed	21
&model->embeddings.embeddings[target_id	7
layer_grad[d]	7
(layer_input[d]	7
target_embed[d])	7
(batch_size	70
(simplified	49
proxy	7
activations)	21
layer--)	14
backward_feed_forward(layer_grad,	7
temp_grad,	42
layer_input,	35
&model->ff_layers[layer],	7
training->ff_grads[layer].w1_lattice,	7
training->ff_grads[layer].w2_lattice,	7
training->ff_grads[layer].bias1,	7
training->ff_grads[layer].bias2);	7
memcpy(layer_grad,	21
backward_attention(layer_grad,	7
&model->attention_layers[layer],	7
training->attention_grads[layer].query_lattice,	7
training->attention_grads[layer].key_lattice,	7
training->attention_grads[layer].value_lattice);	7
backward_layer_norm(layer_grad,	7
&model->layer_norms[layer],	14
training->ln_grads[layer].gamma,	7
training->ln_grads[layer].beta,	7
grad_embed	14
&training->gradients[token_id	7
grad_embed[d]	14
layer_grad[d];	7
(optimization)	77
public	21
interface	14
wrapper	14
that	217
extracts	14
config	112
cllm_backward(cllmtraining*	7
num_tokens)	63
!input_tokens	35
!target_tokens)	42
training->config.batch_size;	49
training->config.sequence_length;	63
(num_tokens	14
cllm_backward_impl(training,	7
"cllm.h"	21
"cllm_inference.h"	14
<time.h>	112
<sys/time.h>	21
<sys/resource.h>	7
timing	7
typedef	238
struct	448
timeval	28
start;	7
end;	21
elapsed_ms;	7
timer;	35
timer_start(timer*	7
timer)	14
gettimeofday(&timer->start,	7
null);	511
timer_stop(timer*	7
gettimeofday(&timer->end,	7
timer->elapsed_ms	7
(timer->end.tv_sec	7
timer->start.tv_sec)	7
1000.0	14
(timer->end.tv_usec	7
timer->start.tv_usec)	7
1000.0;	7
memory	385
usage	63
peak_rss_kb;	7
peak	14
resident	14
current_rss_kb;	7
current	217
heap_size_kb;	7
heap	7
memoryusage;	7
get_memory_usage(memoryusage*	7
usage)	7
rusage	7
r_usage;	7
getrusage(rusage_self,	7
&r_usage);	7
usage->peak_rss_kb	14
r_usage.ru_maxrss;	7
linux,	7
ru_maxrss	7
is	1190
kilobytes	7
macos,	7
it's	63
bytes,	7
so	35
#ifdef	63
__apple__	7
1024;	7
#endif	98
usage->current_rss_kb	7
usage->peak_rss_kb;	7
approximation	161
usage->heap_size_kb	7
malloc_info	7
linux	14
benchmark	84
results	84
inference_time_ms;	7
tokens_per_second;	7
memory_mb;	7
throughput_tokens_per_sec;	7
total_tokens;	14
seq_length;	63
benchmarkresults;	7
benchmarkresults	56
cllm_benchmark_inference_single(cllmmodel*	7
model,	161
input_ids,	35
seq_length,	49
num_iterations)	28
{0};	105
timer	28
memoryusage	28
mem_before,	21
mem_after;	21
(!model	126
!input_ids	14
num_iterations	21
"invalid	49
parameters\n");	21
results;	70
printf("benchmarking	28
inference...\n");	14
length:	70
%zu\n",	196
seq_length);	28
iterations:	28
num_iterations);	28
logits	252
(float*)malloc(model->vocab_size	7
(!logits)	21
"failed	252
buffer\n");	49
get_memory_usage(&mem_before);	21
warm-up	7
run	14
real	63
call	42
actual	112
we'll	14
simulate	42
it	91
runs	7
timer_start(&timer);	28
num_iterations;	63
cllm_forward(model,	7
logits);	7
dummy	49
operation	28
optimization	70
(size_t	1288
model->vocab_size;	217
logits[j]	7
(float)j	28
timer_stop(&timer);	28
final	63
get_memory_usage(&mem_after);	21
results.inference_time_ms	28
timer.elapsed_ms	28
results.tokens_per_second	7
results.inference_time_ms;	28
results.memory_mb	21
(mem_after.peak_rss_kb	21
mem_before.peak_rss_kb)	21
1024.0;	21
results.total_tokens	14
results.seq_length	28
results.batch_size	28
free(logits);	14
printf("results:\n");	28
average	105
time	126
token:	7
%.3f	56
ms\n",	42
results.inference_time_ms);	28
second:	7
%.2f\n",	49
results.tokens_per_second);	7
delta:	28
%.2f	133
mb\n",	70
results.memory_mb);	21
cllm_benchmark_inference_batch(cllmmodel*	7
size:	161
batch_size);	21
(float*)malloc(batch_size	14
logits[b	7
results.throughput_tokens_per_sec	21
seq_length	63
1000.0)	21
batch:	14
throughput:	21
tokens/sec\n",	21
results.throughput_tokens_per_sec);	21
cllm_benchmark_forward_pass(cllmmodel*	7
pass...\n");	7
input_ids	14
(uint32_t*)malloc(batch_size	21
model->embedding_dim	77
(!input_ids	21
buffers\n");	28
(input_ids)	14
free(input_ids);	28
random	77
ids	133
input_ids[i]	14
rand()	28
cllm_forward_complete(model,	7
output);	14
computation	133
model->embedding_dim);	14
time:	98
step	343
cllm_benchmark_training_step(cllmmodel*	7
step...\n");	14
target_ids	7
(float*)malloc(model->num_weights	7
!target_ids	7
!gradients)	42
(target_ids)	7
free(target_ids);	14
(gradients)	7
free(gradients);	14
inputs	7
target_ids[i]	7
(forward	7
optimizer)	7
1.	196
2.	196
3.	168
4.	112
optimizer	175
model->num_weights;	35
gradients[j]	7
comprehensive	35
suite	21
cllm_run_benchmark_suite(cllmmodel*	7
model)	161
(!model)	161
"model	77
null\n");	147
printf("\n");	266
printf("╔════════════════════════════════════════════════════════════╗\n");	28
printf("║	28
║\n");	28
printf("╚════════════════════════════════════════════════════════════╝\n");	28
printf("model	14
configuration:\n");	28
vocabulary	350
%lu\n",	413
(unsigned	357
long)model->vocab_size);	35
dimension:	63
long)model->embedding_dim);	21
layers:	42
model->num_layers);	35
total	378
parameters:	21
long)model->num_weights);	14
test	28
test_seq_len	7
128;	7
test_input	7
(uint32_t*)malloc(test_seq_len	7
(!test_input)	7
input\n");	7
test_seq_len;	7
test_input[i]	7
printf("═══════════════════════════════════════════════════════════\n");	56
printf("1.	14
benchmark\n");	28
cllm_benchmark_inference_single(model,	7
test_input,	14
test_seq_len,	28
100);	7
printf("2.	14
cllm_benchmark_inference_batch(model,	7
8,	35
50);	14
printf("3.	14
cllm_benchmark_forward_pass(model,	7
4,	105
printf("4.	14
cllm_benchmark_training_step(model,	7
20);	7
free(test_input);	7
complete	231
profile	14
over	42
cllm_profile_memory(cllmmodel*	7
duration_seconds)	14
printf("profiling	7
seconds...\n",	14
duration_seconds);	7
time_t	77
start_time	28
time(null);	84
current_time;	7
usage;	7
max_rss	21
min_rss	21
size_max;	7
((current_time	7
time(null))	7
get_memory_usage(&usage);	7
(usage.current_rss_kb	14
max_rss)	7
usage.current_rss_kb;	14
min_rss)	14
[%ld	7
s]	7
rss:	21
current_time	7
start_time,	7
usage.current_rss_kb	7
1024.0);	35
sleep	14
timespec	77
ts	14
{1,	7
0};	7
nanosleep(&ts,	14
printf("\nmemory	14
summary:\n");	7
min	28
(max_rss	7
generate	154
performance	56
report	14
cllm_generate_performance_report(cllmmodel*	7
output_file)	7
file*	238
fp	21
fopen(output_file,	14
"w");	56
(!fp)	21
open	77
file:	77
%s\n",	385
output_file);	14
fprintf(fp,	147
"#	21
report\n\n");	7
"##	21
configuration\n\n");	7
"-	49
%lu	70
(%.2f	42
m)\n",	14
long)model->num_weights,	7
model->num_weights	28
1000000.0);	21
"\n");	21
footprint\n\n");	7
model_size	14
sizeof(float);	63
weights:	35
(1024.0	42
1024.0));	42
tokens:	49
kb\n",	7
(model->vocab_size	7
sizeof(cllmtoken))	14
estimated:	7
(model_size	7
results\n\n");	7
"*(results	7
populated	7
running	21
benchmarks)*\n\n");	7
"---\n");	7
"report	7
generated:	14
%s",	63
ctime(&(time_t){time(null)}));	7
fclose(fp);	28
printf("performance	7
written	7
to:	21
provides	77
cache-aligned	21
allocation	105
improved	21
<stddef.h>	21
_win32	35
<malloc.h>	7
void*	245
cache_aligned_alloc(size_t	7
(size	63
windows:	7
_aligned_malloc	7
_aligned_malloc(size,	7
cache_line_size);	7
#else	49
posix:	7
posix_memalign	7
ptr	7
(posix_memalign(&ptr,	7
cache_line_size,	7
ptr;	7
cache_aligned_free(void*	7
ptr)	14
(!ptr)	7
_aligned_free(ptr);	7
free(ptr);	14
"../include/cllm_training.h"	70
configuration	224
cllm_create_model(const	7
cllmconfig*	49
config)	98
(!config)	70
validate	252
(config->vocab_size	14
config->embedding_dim	112
config->num_layers	56
config->num_heads	28
configuration\n");	28
divisible	35
(config->embedding_dim	28
"embedding_dim	7
num_heads\n");	14
(cllmmodel*)calloc(1,	7
sizeof(cllmmodel));	7
model\n");	14
basic	133
config->vocab_size;	28
config->embedding_dim;	133
model->num_layers	77
config->num_layers;	28
header	119
memcpy(model->header.magic,	7
"cllm",	21
4);	35
model->header.version	7
model->header.vocab_size	7
model->header.embedding_dim	7
model->header.num_layers	7
model->header.num_heads	7
config->num_heads;	21
model->header.context_length	7
config->max_seq_len;	14
model->tokens	28
(cllmtoken*)calloc(config->vocab_size,	7
sizeof(cllmtoken));	21
(!model->tokens)	14
tokens\n");	7
free(model);	70
default	217
model->tokens[i].frequency	21
snprintf(model->tokens[i].token_str,	14
sizeof(model->tokens[i].token_str),	14
"token_%u",	7
i);	280
model->tokens[i].symmetry_group	7
embedding_weights	28
config->vocab_size	28
per-layer	7
attention:	7
3	231
(q,	7
projections)	7
feed-forward:	7
ff_dim	14
(weights	21
biases)	7
norm:	56
4	49
(2	63
norms	63
beta)	7
per_layer_weights	14
config->ff_dim	49
per_layer_weights;	14
model->header.total_params	7
model->weights	70
(float*)calloc(model->num_weights,	7
(!model->weights)	7
weights\n");	7
free(model->tokens);	70
model->embeddings.vocab_size	28
model->embeddings.embedding_dim	7
model->embeddings.embeddings	7
model->weights;	7
embedding_weights;	14
model->embeddings.embeddings[i]	14
((float)rand()	70
rand_max	42
0.5f)	70
model->attention_layers	7
(attentionlayer*)calloc(config->num_layers,	7
sizeof(attentionlayer));	7
(!model->attention_layers)	14
layers\n");	14
free(model->weights);	49
weight_offset	70
model->attention_layers[i].layer_id	7
model->attention_layers[i].num_heads	14
model->attention_layers[i].head_dim	7
assign	42
weight	343
pointers	42
bounds	21
checking	35
qkv_size	14
verify	49
exceed	21
allocated	98
(weight_offset	14
model->num_weights)	21
offset	105
at	273
free(model->attention_layers);	49
model->attention_layers[i].query_lattice	7
weight_offset;	63
qkv_size;	28
model->attention_layers[i].key_lattice	7
model->attention_layers[i].value_lattice	7
xavier	14
initialization	224
xavier_std	7
prime_sqrtf(2.0f	21
config->embedding_dim));	7
model->attention_layers[i].query_lattice[j]	7
xavier_std;	21
model->attention_layers[i].key_lattice[j]	7
model->attention_layers[i].value_lattice[j]	7
model->ff_layers	14
(feedforwardlayer*)calloc(config->num_layers,	7
sizeof(feedforwardlayer));	7
(!model->ff_layers)	14
model->ff_layers[i].layer_id	7
model->ff_layers[i].input_dim	14
model->ff_layers[i].hidden_dim	14
config->ff_dim;	28
model->ff_layers[i].output_dim	7
w1_size	42
w2_size	42
total_ff_size	14
ff	91
free(model->ff_layers);	35
model->ff_layers[i].w1_lattice	7
w1_size;	28
model->ff_layers[i].bias1	7
model->ff_layers[i].w2_lattice	7
w2_size;	28
model->ff_layers[i].bias2	7
he	35
relu/tanh)	7
he_std_w1	7
config->embedding_dim);	14
he_std_w2	7
config->ff_dim);	14
model->ff_layers[i].w1_lattice[j]	7
he_std_w1;	7
model->ff_layers[i].bias1[j]	7
biases	42
model->ff_layers[i].w2_lattice[j]	7
he_std_w2;	7
model->ff_layers[i].bias2[j]	7
model->layer_norms	7
(cllmlayernorm*)calloc(config->num_layers	7
2,	77
sizeof(cllmlayernorm));	14
(!model->layer_norms)	14
norms\n");	7
layer:	35
pre-attention	7
pre-feedforward)	7
model->layer_norms[i].layer_id	7
model->layer_norms[i].dim	7
model->layer_norms[i].epsilon	14
1e-5f;	7
model->layer_norms[i].gamma	7
model->layer_norms[i].beta	7
model->layer_norms[i].gamma[j]	7
1.0f;	308
model->layer_norms[i].beta[j]	7
positional	245
encoding	252
model->pos_encoding.max_length	21
model->pos_encoding.embedding_dim	7
pos_size	14
config->max_seq_len	21
model->pos_encoding.spiral_positions	7
(float*)calloc(config->max_seq_len	28
config->embedding_dim,	28
model->pos_encoding.clock_positions	7
model->pos_encoding.prime_positions	7
model->pos_encoding.learned_positions	7
(!model->pos_encoding.spiral_positions	7
!model->pos_encoding.clock_positions	7
!model->pos_encoding.prime_positions	7
!model->pos_encoding.learned_positions)	7
encodings\n");	7
(model->pos_encoding.spiral_positions)	28
free(model->pos_encoding.spiral_positions);	21
(model->pos_encoding.clock_positions)	21
free(model->pos_encoding.clock_positions);	21
(model->pos_encoding.prime_positions)	21
free(model->pos_encoding.prime_positions);	21
(model->pos_encoding.learned_positions)	28
free(model->pos_encoding.learned_positions);	21
free(model->layer_norms);	21
model;	42
associated	42
cllm_free_model(cllmmodel*	7
(model->layer_norms)	21
(model->ff_layers)	21
(model->attention_layers)	28
(model->weights)	7
(model->tokens)	14
(model->lattice_points)	7
free(model->lattice_points);	14
cllm_estimate_memory(const	7
sizeof(cllmmodel);	21
sizeof(cllmtoken);	14
total_weights	21
sizeof(attentionlayer);	14
sizeof(feedforwardlayer);	14
sizeof(cllmlayernorm);	14
encodings	49
(4	14
types)	7
total;	98
note:	147
cllm_validate_model	7
already	203
defined	28
cllm_utils.c	7
print	189
information	56
cllm_print_model_info(const	7
printf("===	98
===\n");	175
printf("version:	14
model->header.version);	7
printf("vocabulary	28
printf("embedding	14
printf("number	7
printf("total	119
(model->num_layers	21
model->attention_layers)	35
printf("\nattention	7
heads:	21
model->attention_layers[0].num_heads);	14
model->attention_layers[0].head_dim);	14
model->ff_layers)	42
printf("\nfeed-forward	7
model->ff_layers[0].input_dim);	7
model->ff_layers[0].hidden_dim);	14
usage:	14
printf("==============================\n");	7
testing	28
cllm_create_small_model(void)	7
cllmconfig	35
.vocab_size	35
1000,	14
.embedding_dim	35
128,	7
.num_layers	35
.num_heads	35
.ff_dim	35
512,	14
.max_seq_len	35
.dropout	35
0.1f	126
};	126
cllm_create_model(&config);	28
medium	7
cllm_create_medium_model(void)	7
50000,	21
increased	63
coverage	7
1024,	35
richer	14
representations	7
4096,	21
more	140
capacity	35
large	147
cllm_create_large_model(void)	7
12,	56
16,	7
2048,	7
advanced	105
features	105
leverages	14
structure:	7
cvp	28
(closest	14
problem)	28
lookup	56
svp	21
(shortest	14
optimal	98
factorization	98
caching	14
faster	35
spatial	91
indexing	7
"prime_lattice.h"	21
entry	35
factors;	7
num_factors;	7
primefactorization;	7
primefactorization*	35
cache;	14
capacity;	56
primefactorcache;	7
y,	98
z;	21
spatialtoken;	7
spatialtoken*	14
tokens;	56
num_tokens;	105
int*	126
spatial_index;	14
sorted	7
proximity	7
ulamspatialindex;	7
factor	154
primefactorcache*	21
create_prime_factor_cache(int	7
capacity)	28
(primefactorcache*)malloc(sizeof(primefactorcache));	7
cache->cache	7
(primefactorization*)calloc(capacity,	7
sizeof(primefactorization));	14
cache->capacity	7
cache->size	7
free_prime_factor_cache(primefactorcache*	7
cache)	14
(!cache)	14
cache->size;	14
free(cache->cache[i].factors);	7
free(cache->cache);	7
free(cache);	7
factorize	7
into	105
factorize_number(uint32_t	7
uint32_t**	14
*factors	14
possible	7
factors	14
(uint32_t*)malloc(32	7
out	581
2s	7
temp[count++]	21
odd	14
still	28
1,	518
(uint32_t*)malloc(count	14
memcpy(*factors,	7
temp,	42
count;	161
free(temp);	63
(with	7
caching)	7
get_prime_factorization(primefactorcache*	7
(cache->cache[i].number	7
&cache->cache[i];	7
(cache->size	14
cache->capacity)	7
full,	7
replace	35
oldest	14
free(cache->cache[0].factors);	7
memmove(&cache->cache[0],	7
&cache->cache[1],	7
cache->size--;	7
&cache->cache[cache->size++];	7
entry->number	7
factorize_number(n,	7
&entry->factors,	7
&entry->num_factors);	7
entry;	49
fast	42
factorizations	14
fast_gcd_cached(primefactorcache*	7
a,	329
b)	280
(a	77
fa	7
get_prime_factorization(cache,	14
a);	42
fb	7
b);	70
common	84
fa->num_factors	7
fb->num_factors)	7
(fa->factors[i]	14
fb->factors[j])	14
fa->factors[i];	7
i++;	14
j++;	14
gcd;	14
compute_ulam_position(uint32_t	14
z)	7
*x	252
*y	203
*z	21
2.39996322972865332f;	14
2π/φ²	14
prime_sqrtf((float)token_id);	14
(float)token_id	28
prime_cosf(angle);	14
prime_sinf(angle);	14
prime_logf((float)token_id	14
1.0f);	56
ulamspatialindex*	21
create_ulam_spatial_index(uint32_t	7
vocab_size)	140
(ulamspatialindex*)malloc(sizeof(ulamspatialindex));	7
index->num_tokens	7
index->tokens	7
(spatialtoken*)malloc(vocab_size	7
sizeof(spatialtoken));	7
index->spatial_index	7
(int*)malloc(vocab_size	7
sizeof(int));	56
index->tokens[i].token_id	7
compute_ulam_position(i,	7
&index->tokens[i].x,	7
&index->tokens[i].y,	7
&index->tokens[i].z);	7
index->spatial_index[i]	7
index;	14
free_ulam_spatial_index(ulamspatialindex*	7
index)	28
(!index)	7
free(index->tokens);	7
free(index->spatial_index);	7
free(index);	7
spatially	14
close	14
optimization)	21
find_nearby_tokens(ulamspatialindex*	7
index,	14
distances)	7
(uint32_t)index->num_tokens)	7
&index->tokens[token_id];	7
nearby	21
(int*)malloc(k	14
distances	28
all_distances	7
(float*)malloc(index->num_tokens	7
index->num_tokens;	14
dx	77
index->tokens[i].x	7
target->x;	7
dy	84
index->tokens[i].y	7
target->y;	7
dz	49
index->tokens[i].z	7
target->z;	7
all_distances[i]	7
prime_sqrtf(dx*dx	21
dy*dy	35
dz*dz);	35
nearest	91
(simple	63
selection,	7
could	28
heap)	7
k;	28
min_idx	28
min_dist	42
infinity;	49
(all_distances[j]	7
min_dist)	21
selected	14
already_selected	28
m	266
m++)	14
(nearby[m]	7
(!already_selected)	7
all_distances[j];	7
nearby[i]	7
min_idx;	7
(distances)	7
distances[i]	21
min_dist;	7
free(all_distances);	7
nearby;	7
given	35
an	35
closest	49
lattice.	28
accurate	7
than	63
product	175
similarity.	7
cvp_find_closest_token(cllmmodel*	7
query_embedding)	7
!query_embedding)	7
model->embeddings.embeddings;	35
closest_token	14
min_distance	28
minimum	63
euclidean	98
v++)	91
query_embedding[d]	7
embeddings[v	35
d];	56
(distance	7
min_distance)	14
distance;	7
v;	14
closest_token;	7
shortest	56
non-zero	42
can	56
optimize	14
initialization.	7
svp_find_shortest_vector(cllmmodel*	7
(float*)malloc(embed_dim	14
min_length	14
val	147
val;	91
prime_sqrtf(length);	7
(length	7
1e-6f	7
min_length)	7
length;	7
memcpy(shortest,	7
&embeddings[v	7
embed_dim],	7
shortest;	7
factor_cache;	7
use_cvp;	7
use_cached_gcd;	7
crystallineadvancedstate;	7
crystallineadvancedstate*	21
crystalline_advanced_create(cllmmodel*	7
(crystallineadvancedstate*)malloc(sizeof(crystallineadvancedstate));	7
(cache	14
up	175
factorizations)	7
state->factor_cache	7
create_prime_factor_cache(10000);	7
state->spatial_index	7
create_ulam_spatial_index(model->vocab_size);	7
state->use_cvp	7
state->use_cached_gcd	7
printf("advanced	7
initialized\n");	21
printf("-	14
cache:	21
entries\n");	7
index:	7
tokens\n",	56
state;	56
crystalline_advanced_free(crystallineadvancedstate*	7
state)	126
(!state)	140
free_prime_factor_cache(state->factor_cache);	7
free_ulam_spatial_index(state->spatial_index);	7
free(state);	91
similarity	189
crystalline_advanced_similarity(crystallineadvancedstate*	7
state,	154
token1,	35
token2)	21
(!state	98
token1	49
token2	35
enabled	84
(state->use_cached_gcd)	7
shared	91
fast_gcd_cached(state->factor_cache,	7
token2);	14
token2;	28
(float)shared	21
(float)max_val;	28
fallback	105
standard	126
(float)a	7
crystalline_prefetch_nearby(crystallineadvancedstate*	7
k)	42
!model	7
find_nearby_tokens(state->spatial_index,	7
their	7
(hint	7
cpu	84
nearby_token	7
nearby[i];	7
(nearby_token	7
&model->embeddings.embeddings[nearby_token	7
model->embedding_dim];	7
__builtin_prefetch(embedding,	7
3);	77
read,	7
high	7
temporal	7
locality	49
free(nearby);	7
with:	14
q→k	28
reversal	21
(query	7
transformation)	7
hyperdimensional	56
resonance	140
coordinate-based	7
symmetry	602
(rotations,	7
reflections)	7
fourier-based	14
dampening	35
plimpton	63
ratio	112
integration	14
einstein	21
lambda	70
correction	154
cymatic	42
frequency	77
prime-based	98
metrics	182
"../include/prime_lattice_core.h"	14
constants	63
pi	224
3.14159265358979323846	35
#ifndef	7
phi	112
1.618033988749894848	7
einstein_lambda	7
(3.0	7
144000.0)	7
schumann_resonance	14
7.83	7
gamma_burst	14
40.0	7
frequencies	98
(hz)	14
cymatic_freqs[]	7
{432.0f,	7
528.0f,	7
639.0f,	7
741.0f,	7
852.0f,	7
963.0f};	7
num_cymatic_freqs	7
6;	21
ratios	21
babylonian	21
tablet)	7
p;	98
q;	49
ratio;	7
plimptonratio;	7
plimptonratio	14
plimpton_ratios[]	7
{2.0f,	7
1.0f,	14
0.75f},	7
(4-1)/(4+1)	7
3/5	7
{3.0f,	7
2.0f,	14
0.384615f},	7
(9-4)/(9+4)	7
5/13	7
{4.0f,	7
3.0f,	7
0.28f},	7
(16-9)/(16+9)	7
7/25	7
{5.0f,	7
4.0f,	7
0.219512f},	7
(25-16)/(25+16)	7
9/41	7
num_plimpton_ratios	7
4;	168
between	154
two	112
points	84
metric	21
incorporates:	7
space	161
coprimality	7
bonus	14
coords1	7
[3]	35
coords2	7
prime2	21
@return	161
compute_lattice_distance(const	7
coords1,	14
coords2,	14
3d	84
coords1[0]	21
coords2[0];	21
coords1[1]	21
coords2[1];	21
coords1[2]	21
coords2[2];	21
prime_sqrt(dx*dx	14
coprime	28
(gcd=1),	7
maximally	14
different	42
one	168
divides	21
other,	7
similar	21
prime1;	7
prime_similarity	14
(float)gcd);	21
combined	42
weighting	14
prime_similarity;	7
möbius	28
transformation	224
möbius:	7
f(z)	14
(az	14
(cz	14
d)	42
where	112
ad	7
bc	7
≠	7
[seq_len]	56
twist	35
(affects	7
sign)	7
apply_mobius_transform(float*	7
scores,	7
(!scores	7
based	287
(k	49
parity	7
c	308
0.5f;	21
transformation:	7
denominator	28
d;	49
(prime_fabs(denominator)	7
denominator;	7
pythagorean	42
triples	28
adjust	28
geometric	63
relationships	21
apply_plimpton_correction(float*	7
weights,	126
position)	49
(!weights	49
select	14
ratio_idx	7
num_plimpton_ratios;	7
plimpton_ratios[ratio_idx];	7
ratio-based	14
scaling	49
dist	84
abs(i	7
position);	7
scaling:	7
(p²-q²)/(p²+q²)	7
ratio.ratio	7
prime_exp(-dist	7
einstein_lambda);	14
weights[i]	133
scale);	28
modulates	7
harmonic	21
creates	77
patterns	49
apply_cymatic_resonance(float*	7
f	189
num_cymatic_freqs;	7
f++)	14
freq	70
cymatic_freqs[f];	7
phase	70
(float)(i	70
(float)seq_len;	42
prime_cos(phase)	7
(float)num_cymatic_freqs;	7
modulation	56
resonance);	7
schumann	14
dampens	7
earth's	7
natural	42
prevents	14
over-attention	7
apply_schumann_dampening(float*	7
damping_factor	28
100.0f;	14
exponential	49
damping	98
prime_exp(-damping_factor	7
(float)i);	7
damping;	7
burst	21
enhances	7
specific	28
(40	7
hz)	7
mimics	7
neural	14
oscillations	7
apply_gamma_burst(float*	7
40	7
hz	105
0.2f	21
prime_cos(phase);	7
burst;	7
reversal:	7
transform	70
core	63
mechanism.	7
q	84
transformed	28
through:	7
coordinate	56
rotation	119
"if	7
my	7
question,	7
then	42
unknown.	7
have	112
discover	21
it."	7
key_space	14
lattice_coords	28
query_to_key_reversal(const	7
key_space,	21
lattice_coords,	14
!key_space	14
1:	119
rotate	21
golden	182
(φ-based)	7
(phi	28
phi);	42
rotation_angle	14
(float)(prime	21
360);	7
(float)i	28
(float)head_dim;	7
cos_a	84
prime_cos(angle);	70
sin_a	77
prime_sin(angle);	70
2d	21
subspace	7
key_space[i]	21
query[i]	14
query[j]	7
sin_a;	14
2:	112
(lattice_coords)	7
lattice_coords[i]	7
3:	98
prime_scale	7
prime_sqrt((float)prime);	7
prime_scale;	7
computed	35
using:	7
original	42
fourier	49
query_coords	7
key_coords	14
query_prime	7
key_prime	21
compute_hyperdimensional_resonance(const	7
key,	14
query_coords,	7
key_coords,	21
query_prime,	14
key_prime)	14
dot_product	21
key[i];	7
(inverse	7
relationship)	7
lattice_dist	28
(query_coords	7
key_coords)	7
compute_lattice_distance(query_coords,	7
key_prime);	14
lattice_dist);	7
(coprimality)	7
query_prime;	7
key_prime;	7
0.5f	77
(float)(query_prime	14
phase_alignment	7
prime_cos(phase_diff))	7
2.0f;	35
combine	49
components	56
prime_similarity)	7
phase_alignment;	7
resonance;	14
features:	21
lattice-based	28
3]	21
token_primes	21
numbers	70
cllm_crystalline_attention_forward(attentionlayer*	7
token_primes,	7
working	21
(float*)calloc(seq_len	42
embedding_dim,	42
(float*)calloc(head_dim,	7
attention_scores	7
(float*)calloc(seq_len,	7
!attention_scores)	7
free(key_space);	14
free(attention_scores);	14
weights)	35
q_sum	14
k_sum	14
v_sum	14
q_sum;	7
k_sum;	7
v_sum;	7
pos_coords	7
&lattice_coords[pos	7
pos_prime	7
token_primes[pos]	7
query_to_key_reversal(query,	7
pos_coords,	14
pos_prime);	7
&lattice_coords[i	7
token_primes[i]	7
attention_scores[i]	28
compute_hyperdimensional_resonance(	7
pos_prime,	7
);	252
transformations	49
apply_mobius_transform(attention_scores,	7
pos);	28
apply_plimpton_correction(attention_scores,	7
apply_cymatic_resonance(attention_scores,	7
apply_schumann_dampening(attention_scores,	7
apply_gamma_burst(attention_scores,	7
max_score	28
attention_scores[0];	7
(attention_scores[i]	7
max_score)	14
attention_scores[i];	14
prime_exp(attention_scores[i]	7
max_score);	14
&values[i	7
head_output[d]	7
value[d];	7
corrects	7
einstein's	63
cosmological	7
constant	77
explosion	7
cllm_apply_einstein_correction(float*	7
gradients,	168
(!gradients	77
correction:	14
g'	7
g	147
Λ)	7
gradients[i]	112
crystalline-optimized	7
integrates	28
algorithms	35
massive	7
speedup:	14
instead	42
product)	14
(spatial	7
lll	182
reduction	238
(dimension	42
reduction)	7
currently	21
forward/backward.	7
optimizations	35
will	42
re-enabled	7
after	77
works.	7
(euclidean	7
algorithm)	7
o(log	7
complexity	14
vs	14
o(n)	28
gcd(uint32_t	7
much	14
related	21
crystalline_gcd_similarity(uint32_t	7
(token1	7
(shared	14
factors)	28
gcd(token1,	7
[0,	168
ulamposition;	7
ulamposition	42
pos;	70
safety	21
pos.x	14
pos.y	14
pos.z	14
ulam_distance(uint32_t	7
pos1	14
compute_ulam_position(token1);	7
pos2	14
compute_ulam_position(token2);	7
pos1.x	7
pos2.x;	7
pos1.y	7
pos2.y;	7
pos1.z	7
pos2.z;	7
approach	35
cllm_compute_loss_crystalline(cllmtraining*	7
(!training->model)	14
total_loss	273
safety:	7
limit	70
num_tokens	217
safe_num_tokens	14
(safe_num_tokens	7
training->config.batch_size	21
training->config.sequence_length)	7
"warning:	112
(%d)	7
size,	161
clamping\n",	7
num_tokens);	28
safe_num_tokens;	7
input_tokens[i];	21
target_tokens[i];	21
(input	28
training->model->vocab_size	21
training->model->vocab_size)	14
(o(log	7
avoid	56
(which	7
breaks	14
log)	7
crystalline_gcd_similarity(input	7
(tokens	21
related)	7
spatial_similarity	7
ulam_distance(input	7
1));	70
0.7f	7
0.3f	28
spatial_similarity;	7
clamped	14
1e-10f	14
1e-10f;	21
-prime_logf(clamped);	14
sort	28
crystalline_sort_by_locality(uint32_t*	7
tokens,	119
(!tokens	21
bubble	7
(good	7
enough	91
batches)	7
compute_ulam_position(tokens[j]);	7
compute_ulam_position(tokens[j	7
1]);	28
origin	7
dist1	7
prime_sqrtf(pos1.x*pos1.x	7
pos1.y*pos1.y	7
pos1.z*pos1.z);	7
dist2	7
prime_sqrtf(pos2.x*pos2.x	7
pos2.y*pos2.y	7
pos2.z*pos2.z);	7
(dist1	7
dist2)	7
tokens[j];	7
tokens[j]	7
tokens[j	14
1];	91
train	84
epoch	385
enabled:	7
gcd-based	28
provide	14
20-400x	7
speedup	21
cllm_train_epoch_crystalline(cllmtraining*	14
(!training)	77
training->model	21
(!training->tokens	14
training->num_tokens	42
data	266
loaded	35
(tokens=%p,	7
num_tokens=%zu)\n",	7
(void*)training->tokens,	7
training->num_tokens);	28
mode	14
printf("using	14
(20-400x	14
product)\n");	7
printf("training	14
data:	7
%zu	182
sorting	14
disabled	35
input-target	7
correspondence	7
comes	7
similarity,	7
epoch_loss	84
cllm_train_epoch(training);	21
printf("crystalline	7
complete:	28
avg	42
%.4f\n",	147
epoch_loss);	14
epoch_loss;	14
loader	42
loading	14
preprocessing	14
supports:	14
text	280
files	189
(.txt)	7
json	7
documents	28
web	28
scraping	7
pdf	63
extraction	63
(via	7
tools)	7
processing	84
augmentation	7
"../include/cllm_tokenizer.h"	21
<ctype.h>	42
<sys/stat.h>	49
<dirent.h>	42
max_line_length	7
65536	7
max_document_size	7
(100	7
1024	35
1024)	21
100mb	7
document	28
cllmtokenizer*	28
tokenizer;	21
char**	35
documents;	7
num_documents;	7
statistics	434
total_chars;	7
total_lines;	7
min_token_length;	7
max_token_length;	7
lowercase;	7
remove_punctuation;	7
remove_numbers;	7
cllmdataloader;	7
cllmdataloader*	21
cllm_data_loader_create(cllmtokenizer*	7
tokenizer)	28
(!tokenizer)	35
(cllmdataloader*)calloc(1,	7
sizeof(cllmdataloader));	7
(!loader)	21
loader->tokenizer	7
loader->capacity	21
1000;	98
loader->documents	14
(char**)calloc(loader->capacity,	7
sizeof(char*));	28
(!loader->documents)	7
free(loader);	14
loader->min_token_length	7
loader->max_token_length	7
50;	42
loader->lowercase	7
loader->remove_punctuation	7
loader->remove_numbers	7
loader;	7
cllm_data_loader_free(cllmdataloader*	7
loader)	35
(loader->documents)	7
loader->num_documents;	21
free(loader->documents[i]);	7
free(loader->documents);	7
clean	84
applies	14
rules	7
clean_text(const	7
text,	77
(!text)	21
len	154
strlen(text);	21
cleaned	21
(char*)malloc(len	7
(!cleaned)	14
len;	35
char	749
text[i];	21
lowercase	42
(loader->lowercase)	7
tolower(c);	7
remove	112
punctuation	7
(loader->remove_punctuation	7
ispunct(c))	7
(loader->remove_numbers	7
isdigit(c))	7
whitespace	56
(isspace(c))	7
skip	217
multiple	84
spaces	7
cleaned[j-1]	7
'	168
')	7
';	49
cleaned[j++]	7
c;	35
cleaned[j]	7
cleaned;	21
cllm_data_loader_add_document(cllmdataloader*	7
loader,	21
text)	28
(!loader	35
!text)	14
expand	28
(loader->num_documents	14
loader->capacity)	7
new_capacity	70
new_docs	7
(char**)realloc(loader->documents,	7
(!new_docs)	7
new_docs;	7
new_capacity;	42
clean_text(text,	7
loader);	7
loader->documents[loader->num_documents++]	7
loader->total_chars	14
strlen(cleaned);	7
lines	42
(const	21
p	357
*p;	56
p++)	56
(*p	105
'\n')	42
loader->total_lines++;	7
load	238
file	462
cllm_data_loader_load_file(cllmdataloader*	7
filename)	84
!filename)	56
fopen(filename,	63
"r");	77
(!f)	196
filename);	77
fseek(f,	98
seek_end);	56
long	119
file_size	35
ftell(f);	49
seek_set);	56
(file_size	7
max_document_size)	7
"file	28
too	7
large:	7
%s	56
(%ld	14
bytes)\n",	28
filename,	28
file_size);	14
fclose(f);	266
read	329
entire	35
content	77
(char*)malloc(file_size	28
(!content)	21
bytes_read	42
fread(content,	21
file_size,	35
f);	140
content[bytes_read]	21
result	973
cllm_data_loader_add_document(loader,	7
content);	14
free(content);	35
(result)	21
printf("loaded:	7
result;	644
directory	63
recursively	70
loads	21
.txt	7
cllm_data_loader_load_directory(cllmdataloader*	7
dirname)	7
!dirname)	7
dir*	42
dir	42
opendir(dirname);	7
(!dir)	42
directory:	14
dirname);	7
dirent*	42
((entry	42
readdir(dir))	42
.	7
..	7
(strcmp(entry->d_name,	7
".")	7
strcmp(entry->d_name,	7
"..")	7
build	70
path	42
path[1024];	21
snprintf(path,	77
sizeof(path),	77
"%s/%s",	35
dirname,	7
entry->d_name);	49
stat	21
st;	21
(stat(path,	7
&st)	21
(s_isdir(st.st_mode))	7
subdirectory	7
cllm_data_loader_load_directory(loader,	7
path);	7
(s_isreg(st.st_mode))	7
types	56
(not	77
.txt)	49
binary	105
(entry->d_name[0]	77
'.')	77
extensions	49
ext	91
strrchr(entry->d_name,	49
'.');	63
is_binary	98
(ext)	49
(strcmp(ext,	49
".o")	49
strcmp(ext,	441
".so")	49
".a")	49
".bin")	49
".exe")	49
".dll")	49
".png")	49
".jpg")	49
".gif")	49
".pdf")	49
(!is_binary	49
cllm_data_loader_load_file(loader,	49
path))	49
closedir(dir);	42
cllm_data_loader_build_vocab(cllmdataloader*	7
!loader->tokenizer)	14
printf("building	14
documents...\n",	7
loader->num_documents);	28
cllm_build_vocab(loader->tokenizer,	7
loader->documents[i]);	7
loader->total_tokens	14
loader->tokenizer->vocab_size;	7
loader->tokenizer->token_counts[i];	7
built:	7
unique	14
loader->tokenizer->vocab_size,	7
loader->total_tokens);	14
dataset	56
tokenizes	7
sequences	7
tokendataset;	7
tokendataset*	28
cllm_data_loader_create_dataset(cllmdataloader*	7
(tokendataset*)calloc(1,	14
sizeof(tokendataset));	14
(!dataset)	21
dataset->capacity	28
dataset->tokens	21
(uint32_t*)malloc(dataset->capacity	14
(!dataset->tokens)	14
free(dataset);	42
printf("creating	35
dataset...\n");	7
tokenize	77
doc_tokens	7
cllm_tokenizer_encode(loader->tokenizer,	7
loader->documents[i],	7
&num_tokens);	7
(doc_tokens)	7
(dataset->num_tokens	7
dataset->capacity)	7
new_tokens	14
(uint32_t*)realloc(dataset->tokens,	7
(!new_tokens)	14
free(doc_tokens);	14
free(dataset->tokens);	21
new_tokens;	14
memcpy(dataset->tokens	7
dataset->num_tokens,	21
doc_tokens,	7
dataset->num_tokens	7
((i	14
100	49
processed	49
%zu/%zu	7
documents\n",	7
printf("dataset	21
created:	7
dataset->num_tokens);	21
dataset;	14
cllm_token_dataset_free(tokendataset*	7
dataset)	7
save	133
cllm_token_dataset_save(tokendataset*	7
dataset,	7
(!dataset	7
"wb");	42
write	231
fwrite(&dataset->num_tokens,	7
sizeof(size_t),	14
fwrite(dataset->tokens,	7
sizeof(uint32_t),	14
saved	28
(%zu	21
tokens)\n",	21
cllm_token_dataset_load(const	7
(!filename)	7
"rb");	42
(fread(&dataset->num_tokens,	7
f)	56
dataset->num_tokens;	7
(fread(dataset->tokens,	7
dataset->num_tokens)	7
from:	56
cllm_data_loader_print_stats(cllmdataloader*	7
printf("\n===	119
printf("documents:	7
characters:	7
loader->total_chars);	7
lines:	7
loader->total_lines);	7
printf("avg	14
chars	7
document:	7
%.1f\n",	14
(double)loader->total_chars	7
(loader->tokenizer)	7
loader->tokenizer->vocab_size);	7
printf("==============================\n\n");	7
handles	35
embed	28
id	154
[embedding_dim]	35
cllm_embed_token(cllminference*	7
output)	49
inf->model->vocab_size)	7
inf->model;	14
model->embeddings.embedding_dim;	91
[vocab_size	7
embedding_matrix	14
embedding_matrix[offset	14
[dim]	126
[dim	28
dim]	98
cllm_apply_lattice_transform(float*	7
transform,	14
(!embedding	77
!transform	7
(float*)calloc(dim,	14
(!result)	154
matrix-vector	28
multiplication:	35
transform[i	42
embedding[j];	21
result[i]	56
back	91
memcpy(embedding,	14
result,	154
free(result);	42
applied	7
cllm_get_embedding_transformed(cllminference*	7
base	238
cllm_embed_token(inf,	7
(inf->model->embeddings.lattice_transform)	7
cllm_apply_lattice_transform(output,	7
inf->model->embeddings.lattice_transform,	7
inf->model->embeddings.embedding_dim);	7
token_ids	7
[num_tokens]	7
[num_tokens	7
cllm_embed_tokens_batch(cllminference*	7
token_ids,	7
num_tokens,	49
!token_ids	7
inf->model->embeddings.embedding_dim;	14
cllm_get_embedding_transformed(inf,	7
token_ids[i],	7
&output[i	49
embedding_dim]);	7
inverse_transform	7
cllm_apply_inverse_lattice_transform(float*	7
inverse_transform,	14
!inverse_transform	7
cllm_apply_lattice_transform(embedding,	7
hidden_state	7
[vocab_size]	49
cllm_project_to_vocab(cllminference*	7
hidden_state,	14
logits)	28
!hidden_state	7
!logits)	14
(float*)malloc(embedding_dim	7
(!transformed)	7
memcpy(transformed,	7
(model->embeddings.inverse_transform)	28
cllm_apply_inverse_lattice_transform(transformed,	7
model->embeddings.inverse_transform,	7
embedding_dim);	7
transformed[j]	7
logits[i]	63
dot;	14
free(transformed);	7
(l2	14
norm)	7
l2	21
cllm_embedding_norm(float*	7
embedding[i]	70
embedding[i];	28
prime_sqrt(sum);	28
unit	21
cllm_normalize_embedding(float*	7
cllm_embedding_norm(embedding,	7
(norm	84
norm;	112
network	28
position-wise	7
networks	14
transformer	42
declaration	28
cllm_feedforward_free(feedforwardlayer*	14
layer);	14
gelu	21
gelu(x)	21
phi(x)	7
cumulative	7
distribution	98
normal	77
approximation:	14
0.5	35
tanh(sqrt(2/π)	7
0.044715	7
x^3)))	7
gelu(float	7
sqrt_2_over_pi	14
0.7978845608f;	7
sqrt(2/π)	7
coeff	14
0.044715f;	7
x_cubed	7
inner	14
x_cubed);	7
tanh_val;	7
(inner	14
5.0f)	7
-5.0f)	7
exp_2x	7
prime_exp(2.0f	7
inner);	7
(exp_2x	14
1.0f)	119
cllm_activation_gelu(float*	7
gelu(x[i]);	7
cllm_activation_relu(float*	7
0.0f)	350
bias	70
vectorization	14
[output_dim	7
input_dim]	14
[input_dim]	21
[output_dim]	21
matmul_add_bias(float*	7
bias,	14
input_dim,	28
output_dim)	21
multiply	42
simd_matrix_vector_multiply(output,	7
output_dim,	7
input_dim);	7
present	14
(bias)	7
vector_add(output,	7
output_dim);	21
ffn(x)	7
gelu(w1	7
b1)	7
b2	14
cllm_feedforward(feedforwardlayer*	7
layer->input_dim;	14
layer->hidden_dim;	7
layer->output_dim;	14
(float*)malloc(hidden_dim	7
(!hidden)	14
linear	56
b1	7
matmul_add_bias(layer->w1_lattice,	7
layer->bias1,	7
hidden,	14
hidden_dim);	21
cllm_activation_gelu(hidden,	7
matmul_add_bias(layer->w2_lattice,	7
layer->bias2,	7
hidden_dim,	21
(in-place)	7
works	7
when	70
cllm_feedforward_inplace(feedforwardlayer*	7
data)	14
!data)	14
(layer->input_dim	7
layer->output_dim)	7
cannot	91
do	42
in-place	21
dimensions	49
match	28
(float*)malloc(layer->input_dim	7
(!temp)	21
memcpy(temp,	7
data,	49
cllm_feedforward(layer,	14
data);	14
[batch_size	70
output_dim]	7
vectors	140
cllm_feedforward_batch(feedforwardlayer*	7
batch_size)	14
&input[b	14
input_dim],	7
&output[b	14
output_dim]);	7
cllm_feedforward_init(feedforwardlayer*	7
layer->w1_lattice	14
(float*)calloc(w1_size,	7
layer->w2_lattice	14
(float*)calloc(w2_size,	7
layer->bias1	14
layer->bias2	14
(float*)calloc(output_dim,	7
(!layer->w1_lattice	7
!layer->w2_lattice	7
!layer->bias1	7
!layer->bias2)	7
cllm_feedforward_free(layer);	7
(layer->w1_lattice)	7
free(layer->w1_lattice);	7
(layer->w2_lattice)	7
free(layer->w2_lattice);	7
(layer->bias1)	7
free(layer->bias1);	7
(layer->bias2)	7
free(layer->bias2);	7
language	21
(cllm)	7
format	84
revolutionary	21
llm	7
lattices	7
"../include/cllm_format.h"	14
"../include/cllm_utils.h"	7
golden_ratio	7
1.618033988749895	14
symmetry_order	56
12	238
cllm_header_init(cllmheader*	7
header,	7
model_name,	14
description)	7
memset(header,	7
sizeof(cllmheader));	14
magic	14
memcpy(header->magic,	7
"cllm\x01\x00\x00\x00",	14
8);	7
version	140
architecture	35
header->version	14
header->architecture	7
transformer-based	7
(defaults)	7
header->vocab_size	14
50000;	7
header->embedding_dim	14
768;	7
header->num_layers	14
12;	147
header->num_heads	7
header->context_length	7
2048;	7
header->symmetry_order	7
symmetry_order;	35
header->golden_ratio	7
golden_ratio;	7
metadata	70
header->timestamp	7
strncpy(header->model_name,	7
sizeof(header->model_name)	7
strncpy(header->description,	7
description,	7
sizeof(header->description)	7
cllm_prime_to_lattice(uint64_t	7
angle,	119
radius)	21
properties	28
determine	70
modulo	42
order	35
*angle	35
(2.0f	21
(p	28
symmetry_order))	7
*radius	42
prime_powf(golden_ratio,	7
prime_logf(p)	14
prime_logf(2.0f));	7
coords[0]	42
prime_cosf(*angle);	7
coords[1]	42
prime_sinf(*angle);	7
coords[2]	42
prime_logf(golden_ratio);	7
height	70
magnitude	21
primality	21
is_prime(uint64_t	28
num)	7
(num	28
num;	7
cllm_nearest_prime(uint64_t	7
search	56
upward	7
(!is_prime(n))	7
n++;	21
encode	14
cllm_token_to_prime(uint32_t	7
map	126
nth	35
formula	42
prime:	21
p_n	7
ln(n)	56
approx	14
(uint64_t)(prime_logf(token_id	7
cllm_nearest_prime(approx);	7
cllm_token_create(cllmtoken*	7
token,	7
token_str)	7
memset(token,	7
token->prime_encoding	14
cllm_token_to_prime(token_id);	7
cllm_prime_to_lattice(token->prime_encoding,	7
&token->spiral_angle,	7
&token->radial_distance);	7
group	392
token->symmetry_group	7
string	77
sizeof(token->token_str)	7
cllm_lattice_point_create(cllmlatticepoint*	7
point,	14
point_id,	7
z,	28
memset(point,	7
sizeof(cllmlatticepoint));	7
point->point_id	7
point_id;	7
point->coords[0]	7
point->coords[1]	7
point->coords[2]	7
point->prime_factor	7
point->symmetry_group	7
(based	7
properties)	7
point->resonance	7
prime_logf(prime	7
cllm_lattice_distance(const	7
cllmlatticepoint*	21
p1,	14
p2)	7
p1->coords[0]	7
p2->coords[0];	7
p1->coords[1]	7
p2->coords[1];	7
p1->coords[2]	7
p2->coords[2];	7
neighbors	28
cllm_lattice_find_neighbors(cllmlatticepoint*	7
all_points,	7
num_points,	14
max_distance)	14
point->neighbor_count	14
num_points	14
(all_points[i].point_id	7
point->point_id)	7
cllm_lattice_distance(point,	7
&all_points[i]);	7
(dist	56
point->neighbors[point->neighbor_count++]	7
all_points[i].point_id;	7
cllm_validate(const	7
cllmheader	21
header;	21
(fread(&header,	14
sizeof(cllmheader),	21
"error	42
reading	42
file\n");	21
(memcmp(header.magic,	7
(header.version	7
(header.symmetry_order	7
symmetry_order)	14
cllm_free(cllmmodel*	7
free(model->embeddings.embeddings);	7
free(model->embeddings.lattice_transform);	7
free(model->embeddings.inverse_transform);	7
free(model->attention_layers[i].query_lattice);	7
free(model->attention_layers[i].key_lattice);	7
free(model->attention_layers[i].value_lattice);	7
free(model->ff_layers[i].w1_lattice);	7
free(model->ff_layers[i].w2_lattice);	7
free(model->ff_layers[i].bias1);	7
free(model->ff_layers[i].bias2);	7
free(model->layer_norms[i].gamma);	7
free(model->layer_norms[i].beta);	7
cllm_validate_header(const	7
cllmheader*	7
header)	7
(!header)	7
(strncmp(header->magic,	7
4)	49
(header->version	7
100)	63
(header->vocab_size	7
1000000)	21
(header->embedding_dim	7
10000)	7
(header->num_layers	7
disk	28
including	14
configuration.	7
cllm_read_model(const	7
filepath)	70
(!filepath)	7
fopen(filepath,	49
(!file)	14
filepath);	119
file)	28
header\n");	21
fclose(file);	56
(!cllm_validate_header(&header))	7
header.vocab_size,	7
header.embedding_dim,	7
header.num_layers,	7
header.num_heads,	7
header.embedding_dim	14
header.context_length,	7
structure\n");	7
(model->embeddings.embeddings)	42
emb_size	21
(fread(model->embeddings.embeddings,	7
sizeof(float),	182
emb_size,	21
emb_size)	14
cllm_free_model(model);	7
embeddings:	14
floats\n",	21
emb_size);	14
transforms	21
(model->embeddings.lattice_transform)	21
transform_size	28
fread(model->embeddings.lattice_transform,	7
transform_size,	42
file);	126
(read	21
transform_size)	14
expected	91
floats,	14
lattice_transform\n",	7
read);	14
fread(model->embeddings.inverse_transform,	7
inverse_transform\n",	7
attn	56
d_model	126
(attn->query_lattice)	35
fread(attn->query_lattice,	7
d_model,	63
(void)read;	49
(attn->key_lattice)	28
fread(attn->key_lattice,	7
(attn->value_lattice)	28
fread(attn->value_lattice,	7
feedforward	42
(ff->w1_lattice)	14
fread(ff->w1_lattice,	7
ff->input_dim	28
ff->hidden_dim,	28
(ff->bias1)	14
fread(ff->bias1,	7
(ff->w2_lattice)	14
fread(ff->w2_lattice,	7
ff->hidden_dim	49
ff->output_dim,	28
(ff->bias2)	14
fread(ff->bias2,	7
printf("✓	182
loaded:	21
vocab:	7
|	224
embedding:	7
long)header.vocab_size,	7
long)header.embedding_dim,	7
long)header.num_layers);	7
cllm_write_model(const	7
!filepath)	28
-1;	847
memset(&header,	7
memcpy(header.magic,	7
memcpy	7
strncpy	7
non-null-terminated	7
header.version	7
header.vocab_size	7
header.num_layers	7
header.num_heads	7
header.context_length	7
512;	21
model's	28
recalculating	7
header.total_params	7
(fwrite(&header,	7
(fwrite(model->embeddings.embeddings,	7
fwrite(model->embeddings.lattice_transform,	7
fwrite(model->embeddings.inverse_transform,	7
fwrite(attn->query_lattice,	7
fwrite(attn->key_lattice,	7
fwrite(attn->value_lattice,	7
fwrite(ff->w1_lattice,	7
fwrite(ff->bias1,	7
fwrite(ff->w2_lattice,	7
fwrite(ff->bias2,	7
saved:	35
embeddings\n",	14
fp16	42
mixed	35
fp32	49
<stdint.h>	42
"../include/cllm_fp16.h"	7
software	28
(fallback)	14
uint16_t	42
fp32_to_fp16_scalar(float	7
value)	70
f32	35
*((uint32_t*)&value);	7
sign	105
(f32	14
>>	119
16)	21
&	266
0x8000;	7
exponent	84
((f32	7
23)	21
0xff)	7
127	21
15;	7
mantissa	56
13)	21
0x3ff;	21
handle	210
special	161
cases	35
(exponent	35
underflow	7
(uint16_t)sign;	7
31)	21
infinity	77
(uint16_t)(sign	14
0x7c00);	7
<<	154
10)	35
mantissa);	7
fp16_to_fp32_scalar(uint16_t	7
(value	56
0x8000)	7
16;	14
0x1f;	7
f32;	7
(mantissa	28
sign;	14
denormalized	7
((mantissa	7
0x400)	7
<<=	7
exponent--;	7
&=	7
((exponent	14
15)	14
13);	28
nan	105
0x7f800000	7
*((float*)&f32);	7
f16c	28
instructions	28
fp32_to_fp16(uint16_t*	7
fp16,	14
fp32,	14
__f16c__	14
hardware	14
n_vec	49
n_vec;	70
_mm256_loadu_ps(&fp32[i]);	7
__m128i	14
_mm256_cvtps_ph(v,	7
_mm_fround_to_nearest_int);	7
_mm_storeu_si128((__m128i*)&fp16[i],	7
h);	14
fp16[i]	14
fp32_to_fp16_scalar(fp32[i]);	14
fp16_to_fp32(float*	7
uint16_t*	7
_mm_loadu_si128((__m128i*)&fp16[i]);	7
_mm256_cvtph_ps(h);	7
_mm256_storeu_ps(&fp32[i],	7
v);	14
fp32[i]	14
fp16_to_fp32_scalar(fp16[i]);	14
scale_fp32_array(float*	7
scale)	49
vscale	7
_mm256_set1_ps(scale);	14
_mm256_loadu_ps(&data[i]);	7
_mm256_mul_ps(v,	7
vscale);	7
_mm256_storeu_ps(&data[i],	7
data[i]	14
has_nan_or_inf(const	7
(prime_isnanf(data[i])	7
prime_isinff(data[i]))	7
"prime_math.h"	14
max_sequence_length	14
512	21
temperature_min	7
temperature_max	7
context	140
cllminference*	14
cllm_inference_init(cllmmodel*	7
(cllminference*)calloc(1,	7
sizeof(cllminference));	7
(!inference)	14
context\n");	7
inference->model	7
inference->temperature	14
inference->top_p	14
0.9f;	28
inference->top_k	14
inference->max_tokens	21
inference->hidden_states	7
(float*)calloc(embed_dim,	28
inference->logits	7
(float*)calloc(vocab_size,	7
(!inference->hidden_states	7
!inference->logits)	7
cllm_inference_cleanup(inference);	7
printf("inference	7
successfully\n");	35
inference;	7
cllm_inference_cleanup(cllminference*	7
inference)	7
(inference->hidden_states)	7
free(inference->hidden_states);	7
(inference->logits)	7
free(inference->logits);	7
free(inference);	7
cllm_get_embedding(cllminference*	7
inference,	70
(!inference	42
inference->model;	21
memcpy(output,	7
fixed	28
cllm_tokenize(cllminference*	7
max_tokens)	63
!text	28
!tokens)	7
exists	63
(!inference->model->tokens)	14
character-based	35
tokenization\n");	14
fallback:	35
max_tokens	35
max_tokens;	21
tokens[i]	7
(uint32_t)(text[i]	7
inference->model->vocab_size);	14
token_count	56
buffer[256];	14
buf_pos	28
text[i]	28
(text[i]	7
'\n'	28
'\t')	14
(buf_pos	42
buffer[buf_pos]	28
found	168
inference->model->vocab_size;	28
(strcmp(inference->model->tokens[j].token_str,	14
buffer)	70
tokens[token_count++]	56
unknown	42
words	14
hash	273
(like	7
does)	7
(!found)	49
buffer[k];	14
31	42
(uint32_t)buffer[k];	14
255)	21
buffer[buf_pos++]	14
last	70
token_count;	35
detokenize	28
cllm_detokenize(cllminference*	7
max_length)	28
!tokens	35
detokenization\n");	7
characters	21
max_length	63
output[pos++]	21
(char)(tokens[i]	7
128);	21
ascii	7
range	196
output[pos]	21
(tokens[i]	14
inference->model->vocab_size)	7
token_str	28
inference->model->tokens[tokens[i]].token_str;	7
(pad,	7
unk,	7
bos,	7
eos,	7
(token_str[0]	7
'<'	7
token_str[strlen(token_str)-1]	7
'>')	21
like	14
<pad>,	7
<unk>,	7
etc.	35
strlen(token_str);	21
(pos	28
strcpy(&output[pos],	14
token_str);	21
cllm_apply_positional_encoding(cllminference*	7
hidden_states,	7
!hidden_states)	7
(position	28
(int)model->pos_encoding.max_length)	7
pos_enc	56
&model->pos_encoding.spiral_positions[position	7
hidden_states[i]	7
pos_enc[i];	7
(old	7
compatibility)	7
cllm_layer_norm_old(float*	7
ln->epsilon);	7
learned	28
(ln->gamma	7
ln->beta)	14
ln->gamma[i]	42
ln->beta[i];	14
cllm_feed_forward(float*	7
ff)	7
->	35
(ff->w1_lattice	7
ff->bias1)	21
hidden[i]	21
ff->bias1[i];	7
x[j]	7
ff->w1_lattice[j	7
(hidden[i]	7
(ff->w2_lattice	7
ff->bias2)	21
ff->bias2[i];	7
hidden[j]	7
ff->w2_lattice[j	7
cllm_forward(cllminference*	7
cllm_forward\n");	7
critical	42
(!inference->hidden_states)	7
hidden_states	7
(!inference->logits)	7
last_token	7
tokens[num_tokens	7
(last_token	7
(vocab_size=%lu)\n",	7
last_token,	14
cllm_get_embedding(inference,	7
inference->hidden_states);	7
cllm_apply_positional_encoding(inference,	7
inference->hidden_states,	14
(model->attention_layers	21
model->layer_norms)	28
attn_output	14
(!attn_output)	7
layer++)	91
cllm_layer_norm_old(inference->hidden_states,	14
attn_layer	14
&model->attention_layers[layer];	28
cllm_attention_forward(attn_layer,	14
attn_output,	14
null,	147
states	28
memcpy(inference->hidden_states,	7
cllm_feed_forward(inference->hidden_states,	7
&model->ff_layers[layer]);	7
free(attn_output);	7
&model->layer_norms[model->num_layers	7
1],	21
inference->logits[i]	14
token_embed	7
&model->embeddings.embeddings[i	7
inference->hidden_states[j]	7
token_embed[j];	7
temperature	49
cllm_apply_temperature(float*	7
logits,	112
temperature)	14
(temperature	28
temperature_min)	14
temperature_min;	14
temperature_max)	14
temperature_max;	14
temperature;	14
cllm_softmax(float*	7
max_logit	133
logits[0];	35
(logits[i]	35
max_logit)	70
logits[i];	63
prime_expf(logits[i]	14
max_logit);	49
sample	56
top-k	56
cllm_sample_top_k(float*	7
probs,	14
sampling	7
r	182
(float)rand()	21
rand_max;	21
cumsum	42
probs[i];	14
(r	14
cumsum)	21
top-p	7
(nucleus	7
sampling)	7
cllm_sample_top_p(float*	7
p)	35
(cumsum	7
cllm_generate(cllminference*	7
prompt,	14
max_output_length)	7
!prompt	7
silent	21
generation	84
terminal	21
spam	21
prompt	7
tokens[max_sequence_length];	7
cllm_tokenize(inference,	7
max_sequence_length);	7
strcpy(output,	7
prompt");	7
tokens_generated	7
(tokens_generated	7
max_sequence_length)	7
cllm_forward(inference,	7
cllm_apply_temperature(inference->logits,	7
inference->model->vocab_size,	21
inference->temperature);	7
cllm_softmax(inference->logits,	7
next_token;	14
(inference->top_k	7
next_token	14
cllm_sample_top_k(inference->logits,	7
inference->top_k);	7
cllm_sample_top_p(inference->logits,	7
inference->top_p);	7
tokens[num_tokens++]	7
tokens_generated++;	7
cllm_detokenize(inference,	7
max_output_length);	7
tokens_generated;	7
cllm_set_temperature(cllminference*	7
(inference)	28
cllm_set_top_p(cllminference*	7
top_p)	7
(top_p	14
top_p	14
top_p;	7
cllm_set_top_k(cllminference*	7
top_k)	7
top_k	14
cllm_set_max_tokens(cllminference*	7
cllm_sample_token(cllminference*	7
inf->model->vocab_size;	7
(inf->temperature	7
inf->temperature;	7
probabilities	35
various	14
strategies	14
networks:	7
xavier/glorot	21
sigmoid/tanh	7
relu/gelu	7
orthogonal	70
recurrent	14
connections)	7
zero/uniform/normal	7
layer-specific	7
mathematical	91
foundations:	7
xavier:	7
var(w)	14
2/(n_in	7
n_out)	35
he:	7
2/n_in	7
orthogonal:	7
w^t	7
w	105
include	7
rng_initialized	21
ensure_rng_initialized(void)	7
(!rng_initialized)	7
srand((unsigned	7
int)time(null));	7
uniform	63
uniform_random(void)	7
(double)rand()	7
(double)rand_max;	7
[a,	14
b]	21
uniform_random_range(double	7
a)	7
uniform_random();	7
box-muller	7
normal_random(double	7
mean,	21
stddev)	14
has_spare	21
spare;	14
(has_spare)	7
stddev	35
u,	28
v,	63
u	35
uniform_random()	14
2.0	147
(s	7
0.0);	21
spare	7
samples	49
distribution:	28
best	84
for:	42
sigmoid,	14
cllm_init_xavier_uniform(double*	7
n_in,	35
(!weights)	63
ensure_rng_initialized();	49
n_in	28
n_out;	35
prime_sqrt(6.0	14
(double)(n_in	14
n_out));	14
uniform_random_range(-limit,	14
limit);	14
cllm_init_xavier_normal(double*	7
prime_sqrt(2.0	14
normal_random(0.0,	21
stddev);	28
relu,	14
gelu,	14
leaky	14
cllm_init_he_uniform(double*	7
(double)n_in);	14
recommended	7
transformers	7
cllm_init_he_normal(double*	7
initializes	63
qr	28
decomposition	35
useful	7
connections	7
deep	14
algorithm:	63
n(0,1)	7
perform	28
cllm_init_orthogonal(double*	7
n_out,	7
gain)	7
rows	21
cols	70
n_in;	7
gram-schmidt	77
orthogonalization	42
qr)	14
column,	7
orthogonalize	14
against	14
previous	42
columns	21
column	14
0..j-1	7
weights[i	49
k];	21
subtract	70
-=	336
1e-10)	42
gain	14
(gain	7
gain;	7
typically	28
cllm_init_zeros(double*	7
cllm_init_constant(double*	7
value;	42
u[a,	7
cllm_init_uniform(double*	7
uniform_random_range(a,	7
n(mean,	7
stddev^2)	7
cllm_init_normal(double*	7
normal_random(mean,	7
deviation	21
cllm_init_embedding_layer(embeddings*	7
embed)	7
(!embed	7
!embed->embeddings)	7
0.02;	7
embed->vocab_size	7
embed->embedding_dim;	7
double*	371
(double*)malloc(total	42
sizeof(double));	77
cllm_init_normal(temp,	7
total,	7
0.0,	42
embed->embeddings[i]	7
(float)temp[i];	42
cllm_init_attention_layer(attentionlayer*	7
attn)	7
(!attn)	14
attn->num_heads;	14
d_model;	49
(temp)	35
cllm_init_xavier_uniform(temp,	21
d_model);	21
attn->query_lattice[i]	14
attn->key_lattice[i]	14
attn->value_lattice[i]	14
(gelu	7
activation)	7
cllm_init_feedforward_layer(feedforwardlayer*	7
ffn)	7
(!ffn)	7
ffn->input_dim;	7
ffn->hidden_dim;	14
ffn->output_dim;	21
(input_dim	7
hidden_dim)	7
(ffn->w1_lattice)	14
cllm_init_he_normal(temp,	14
ffn->w1_lattice[i]	7
(ffn->bias1)	7
ffn->bias1[i]	7
(hidden_dim	7
(ffn->w2_lattice)	14
ffn->w2_lattice[i]	7
(ffn->bias2)	7
ffn->bias2[i]	7
(scale)	14
(shift)	14
cllm_init_layernorm(layernorm*	7
ln)	21
(!ln)	21
ln->size;	7
(ln->gamma)	28
shift	91
(ln->beta)	28
ln->beta[i]	28
cllm_init_cllm_layernorm(cllmlayernorm*	7
ln->dim;	35
appropriate	14
cllm_init_model(cllmmodel*	7
cllm_init_embedding_layer(&model->embeddings);	7
cllm_init_attention_layer(&model->attention_layers[i]);	7
cllm_init_feedforward_layer(&model->ff_layers[i]);	7
(cllmlayernorm	7
type)	42
cllm_init_cllm_layernorm(&model->layer_norms[i	14
2]);	7
ln1	7
ln2	7
seed	21
allows	14
custom	70
cllm_init_model_with_seed(cllmmodel*	7
unsigned	35
seed)	7
srand(seed);	7
strategy	56
cllm_init_model(model);	7
generates	14
"../include/prime_math.h"	35
prime_types.h	28
trial	28
division)	7
otherwise	77
(uint64_t)prime_sqrt((double)n);	14
(0-based)	7
get_nth_prime(uint32_t	14
start	224
(is_prime(candidate))	21
mapping	147
output:	126
radial	49
center	28
cllm_compute_spiral_position(uint64_t	7
(!angle	14
!radius)	14
(is_prime(p))	7
prime_index++;	7
p++;	91
spiral:	35
grows	14
prime_sqrt((float)prime_index);	7
packing	35
137.5°	7
(float)prime_index;	14
2π)	63
(*angle	7
pi)	35
coords	7
[x,	7
z]	7
cllm_map_token_to_lattice(uint32_t	7
coords)	14
cllm_compute_spiral_position(prime,	7
&radius);	7
cylindrical	7
polar	28
depth	70
logarithmic	28
z-axis	7
prime_log((float)prime	14
token-specific	14
perturbation	21
uniqueness	7
token_phase	14
1000.0f;	21
prime_cos(token_phase);	14
prime_sin(token_phase);	14
prime_sin(token_phase	14
(0	63
symmetry_order-1)	28
cllm_compute_symmetry_group_internal(uint64_t	7
symmetry_order);	14
cllm_generate_lattice_embedding(uint32_t	7
coords[3];	14
cllm_map_token_to_lattice(token_id,	14
coords);	14
cllm_compute_symmetry_group_internal(prime);	14
smooth,	7
continuous	42
prime_sin(freq	35
10.0f)	28
prime_cos(freq	35
0.3f;	7
symmetry-based	7
component	35
symmetry_phase	7
(float)symmetry	7
(float)symmetry_order;	28
symmetry_component	7
symmetry_phase)	7
symmetry_component;	7
output[i];	14
prime_sqrt(norm);	49
cllm_generate_lattice_embeddings(cllmmodel*	7
!model->embeddings.embeddings)	7
model->embeddings.vocab_size;	7
printf("generating	28
tokens...\n",	7
vocab_size);	84
token_id++)	7
get_nth_prime(token_id);	7
cllm_generate_lattice_embedding(token_id,	7
embedding);	7
(model->tokens	7
model->tokens[token_id].prime_encoding	7
model->tokens[token_id].lattice_coords[0]	7
coords[0];	7
model->tokens[token_id].lattice_coords[1]	7
coords[1];	7
model->tokens[token_id].lattice_coords[2]	7
coords[2];	7
model->tokens[token_id].symmetry_group	7
((token_id	7
1000	56
generated	7
%u/%u	7
printf("lattice	7
complete!\n");	49
cllm_generate_lattice_transform(float*	7
(!transform	7
memset(transform,	7
i]	63
rotations	7
preserves	7
(float)dim;	35
givens	7
plane	21
(i,	7
i+1)	7
temp_ii	21
temp_i_ip1	21
1)];	14
temp_ip1_i	7
transform[(i	28
temp_ip1_ip1	7
temp_ip1_i;	14
1)]	14
temp_ip1_ip1;	14
token1_id	7
token2_id	7
cllm_lattice_token_distance(uint32_t	7
token1_id,	7
token2_id,	7
coords1[3],	7
coords2[3];	7
cllm_map_token_to_lattice(token1_id,	7
coords1);	7
cllm_map_token_to_lattice(token2_id,	7
coords2);	7
prime_sqrt(dx	21
dz);	7
all_tokens	7
all_primes	7
neighbor	7
cllm_find_lattice_neighbors(uint32_t	7
all_tokens,	7
all_primes,	7
neighbors)	7
(!all_tokens	7
!all_primes	7
!neighbors	7
(float*)malloc(num_tokens	7
(!distances)	7
(all_tokens[i]	7
1e9f;	21
exclude	7
self	7
cllm_lattice_token_distance(token_id,	7
all_tokens[i],	7
all_primes[i]);	7
smallest	21
selection)	7
(int)num_tokens;	7
distances[0];	7
(distances[j]	7
distances[j];	7
neighbors[i]	7
all_tokens[min_idx];	7
distances[min_idx]	7
mark	35
free(distances);	7
lattice-aware	7
cllm_lattice_aware_init(cllmmodel*	7
!model->weights)	28
total_weights;	7
random_val	56
rand_max)	28
model->weights[i]	7
cllm_crystalline_init(cllmmodel*	7
base_scale)	14
hidden_size	56
periodic	7
hidden_size;	28
sine	49
wave	14
(float)(vocab_size	7
hidden_size);	7
pattern	21
prime_sinf(2.0f	7
3.141592653589793	14
phase);	14
model->weights[idx]	21
(pattern	7
0.7f)	7
base_scale;	7
symmetry-preserving	7
cllm_symmetric_init(cllmmodel*	7
half	42
randomly	7
mirror	21
src_idx	7
dst_idx	7
i)	28
model->weights[dst_idx]	7
model->weights[src_idx];	7
hierarchical	63
cllm_hierarchical_lattice_init(cllmmodel*	7
num_levels,	7
!model->weights	14
num_levels	14
divide	49
levels	14
level_size	7
num_levels;	42
level	168
level++)	21
level_scale	7
base_scale	7
(float)(level	7
start_idx	28
level_size;	14
end_idx	14
(level	21
(end_idx	7
start_idx;	7
end_idx;	7
level_scale;	7
layernorm(x)	7
sqrt(variance	7
epsilon)	49
ln	56
cllm_layer_norm(cllmlayernorm*	7
(!ln	28
epsilon	112
ln->epsilon;	7
input[i];	14
input[i]	21
prime_sqrt(variance	7
epsilon);	42
affine	7
(input[i]	7
cllm_layer_norm_inplace(cllmlayernorm*	7
cllm_layer_norm(ln,	14
cllm_layer_norm_batch(cllmlayernorm*	7
dim]);	7
cllm_layer_norm_init(cllmlayernorm*	7
ln->dim	7
ln->epsilon	7
epsilon;	7
ln->gamma	14
(float*)malloc(dim	35
ln->beta	14
free(ln->gamma);	14
free(ln->beta);	14
cllm_layer_norm_free(cllmlayernorm*	7
debugging/analysis)	7
cllm_layer_norm_stats(float*	7
variance)	7
!mean	7
!variance)	7
*mean	21
*variance	21
*mean;	7
reduces	14
dimensionality	28
covariance	42
onto	28
reduced	91
(fewer	7
parameters)	7
2-4x	7
128	21
→	49
64	28
32)	21
"prime_matrix.h"	7
float**	63
(reduced_dim	7
×	280
original_dim)	14
inverse_basis;	7
reconstruction	14
original_dim;	28
reduced_dim;	21
temp_buffer;	7
lllembeddingreducer;	7
compute_embedding_covariance(cllmmodel*	7
cov	14
(float**)malloc(embed_dim	7
sizeof(float*));	56
cov[i]	7
mean[d]	14
xi	14
mean[i];	7
xj	7
mean[j];	7
cov[i][j]	14
xj;	7
free(mean);	7
cov;	7
pca-like	7
requires	21
complex	21
integration)	7
apply_lll_reduction(float**	7
cov_matrix,	7
target_dim)	21
printf("applying	21
reduction:	49
dimensions\n",	14
target_dim);	28
approach:	14
extract	161
top	42
eigenvectors	7
production,	21
algorithm	119
(float**)malloc(target_dim	7
target_dim;	21
memcpy(basis[i],	7
cov_matrix[i],	7
basis[i][j]	14
basis[i][j];	7
prime_sqrtf(norm);	21
printf("dimensionality	7
complete\n");	14
pseudo-inverse	14
compute_pseudo_inverse(float**	7
reduced_dim,	7
transpose	14
todo:	168
implement	119
moore-penrose	7
(float**)malloc(original_dim	7
inverse[i]	7
(float*)calloc(reduced_dim,	7
inverse[i][j]	21
basis[j][i];	7
inverse[i][j];	7
inverse;	7
reducer	49
lllembeddingreducer*	21
lll_reducer_create(cllmmodel*	7
target_dim	14
(int)model->embedding_dim)	7
reducer:	7
long)model->embedding_dim,	7
(lllembeddingreducer*)calloc(1,	7
sizeof(lllembeddingreducer));	7
reducer->original_dim	7
reducer->reduced_dim	14
compute_embedding_covariance(model);	7
reducer->basis	7
apply_lll_reduction(cov,	7
model->embedding_dim,	21
(!reducer->basis)	7
free(reducer);	14
free(cov[i]);	14
free(cov);	14
reducer->inverse_basis	7
compute_pseudo_inverse(reducer->basis,	7
target_dim,	14
reducer->temp_buffer	7
(float*)malloc(model->embedding_dim	7
printf("lll	14
created	35
reducer;	7
lll_reducer_free(lllembeddingreducer*	7
reducer)	7
(!reducer)	14
(reducer->basis)	7
reducer->reduced_dim;	21
free(reducer->basis[i]);	7
free(reducer->basis);	7
(reducer->inverse_basis)	7
reducer->original_dim;	21
free(reducer->inverse_basis[i]);	7
free(reducer->inverse_basis);	7
free(reducer->temp_buffer);	7
lll_project_embedding(lllembeddingreducer*	7
reducer,	21
reduced)	7
(!reducer	21
!embedding	14
!reduced)	7
reduced[i]	14
reducer->basis[i][j]	7
reconstruct	14
lll_reconstruct_embedding(lllembeddingreducer*	7
reduced,	7
!reduced	7
!embedding)	7
inverse_basis	7
reducer->inverse_basis[i][j]	7
reduced[j];	7
lll_project_all_embeddings(lllembeddingreducer*	7
!model)	7
reduced_embeddings	14
(float*)malloc(vocab_size	28
&model->embeddings.embeddings[v	14
reducer->original_dim];	7
&reduced_embeddings[v	7
reducer->reduced_dim];	7
lll_project_embedding(reducer,	7
original,	7
reduced);	7
reduced_embeddings;	14
integrate	7
lll_integrate_training(cllmtraining*	7
integrating	7
lll_reducer_create(training->model,	7
reducer\n");	7
lll_project_all_embeddings(reducer,	7
training->model);	7
free(training->model->embeddings.embeddings);	7
training->model->embeddings.embeddings	7
training->model->embedding_dim	7
free(training->gradients);	14
training->gradients	21
(float*)calloc(training->model->vocab_size	7
integrated:	7
reducer->original_dim,	7
reducer->reduced_dim);	7
printf("parameter	14
%.1fx\n",	7
(float)reducer->original_dim	7
(float)reducer->reduced_dim);	7
freed	21
here,	7
but	70
production	42
you'd	14
want	21
keep	21
reconstructing	7
during	49
lll_reducer_free(reducer);	7
[size]	105
softmax_inplace(float*	7
(!logits	77
prime_exp(logits[i]	7
cross-entropy	77
-log(p(target))	14
predicted	70
cllm_compute_cross_entropy_loss(float*	7
target,	35
(uint32_t)vocab_size	21
probs	42
(!probs)	35
memcpy(probs,	21
softmax_inplace(probs,	21
loss:	140
-prime_log(probs[target]	7
1e-8f);	21
free(probs);	21
loss;	112
p(predicted)	7
1[target]	21
one-hot	7
cllm_compute_loss_gradient(float*	7
grad_output,	21
!grad_output	21
memcpy(grad_output,	7
softmax_inplace(grad_output,	7
position:	21
grad	224
grad_output[target]	7
vocab_size]	28
